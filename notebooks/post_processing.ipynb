{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d108cf1-bc92-4284-9105-9506c4f7139e",
   "metadata": {},
   "source": [
    "# [Oregon Statewide ET Project](https://www.dri.edu/project/owrd-et/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef52be5-1a4d-40f9-890a-8f3bf02484de",
   "metadata": {},
   "source": [
    "## **Post-Processing Workflow**\n",
    " \n",
    "## Steps: \n",
    "1. Concatenate individual static & annual tables (creates one table per year)\n",
    "2. Join ET Demands data to field summaries\n",
    "3. Gap-fill EToF using linear interpolation (1 mo) or climatologies (2+ mo)\n",
    "   * **NOTE**: This step requires all individual annual tables within the respective gap-filling window to be processed in the previous step (i.e., ET Demands join)\n",
    "   * Start/End year options for each gap-filling window:\n",
    "    > 1985-1991<br>\n",
    "    > 1992-1997<br>\n",
    "    > 1998-2003<br>\n",
    "    > 2004-2009<br>\n",
    "    > 2010-2015<br>\n",
    "    > 2016-2022\n",
    "4. Soil moisture carry forward and applied water calculations\n",
    "5. HUC8/HUC12 aggregations\n",
    "6. HUC-level geodatabase preparation with Google Earth Engine (GEE)\n",
    "<br>\n",
    "\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db3fb86b-e85e-44b9-9f66-e78b19f1efd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------PARAMETERS---------------------------------------------------------\n",
    "\n",
    "# path to GEE export folder where tables are stored\n",
    "table_path = r'E:\\dri-owrd-et\\tables\\ee_exports'\n",
    "\n",
    "# flag for testing post-processing for a single field\n",
    "test_flag = True\n",
    "\n",
    "# define start/end years for exports\n",
    "start_year = 1985\n",
    "end_year = 1991\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b782f5b8-d9a4-49ff-a6af-c546ad554a80",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e718aa-cb25-4b19-bb38-c18dceda611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffbe6a0-58b3-46af-a590-fcf815c3d292",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Concatenate individual static & annual tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3467499-7499-4b87-b986-29aa30af0317",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################################################################\n",
    "\n",
    "# shapefile location\n",
    "shp_path = table_path.replace('tables\\\\ee_exports', 'shapefiles')\n",
    "\n",
    "# output location\n",
    "out_path = table_path.replace('ee_exports', 'post_processing\\\\2_for_et_demands_join')\n",
    "\n",
    "# list of years to process based on start/end year\n",
    "year_list = list(range(start_year, end_year+1))\n",
    "\n",
    "###################################################################\n",
    "\n",
    "### static attributes\n",
    "# huc attributes\n",
    "df_huc = pd.read_csv(os.path.join(table_path, 'or_field_summaries_huc_attributes.csv'), index_col='OPENET_ID')\n",
    "\n",
    "# annual crop type and gridmet ID attributes \n",
    "df_c_pre = pd.read_csv(os.path.join(table_path, 'crop_type_codes_and_gridmet_cells.csv'), index_col='OPENET_ID')\n",
    "\n",
    "# irrigation system type, irrigation source type, efficiencies, and OWRD admin boundary attributes\n",
    "df_typ = gpd.read_file(os.path.join(shp_path, 'Oregon_Hyd_Area_Ag_Boundaries_20241016.shp'))[['OPENET_ID', 'ITYPE', 'srctype', 'IRR_EFF', 'OWRD']]\n",
    "df_typ = df_typ.set_index('OPENET_ID')\n",
    "\n",
    "# fill blank srctypes and efficiencies with 0's\n",
    "df_typ.loc[df_typ['srctype'].isnull(), 'srctype'] = 0\n",
    "df_typ.loc[df_typ['IRR_EFF'].isnull(), 'IRR_EFF'] = 0\n",
    "\n",
    "# cuenca region attributes\n",
    "df_cue = pd.read_csv(os.path.join(table_path, 'cuenca_regions.csv'), index_col='OPENET_ID')\n",
    "df_cue = df_cue.fillna(0)\n",
    "\n",
    "# bad geometries identified and need to be removed\n",
    "df_bad = pd.read_csv(os.path.join(table_path, 'bad_geometry_list.csv'), index_col='OPENET_ID')\n",
    "bad_list = list(df_bad.index)\n",
    "\n",
    "# only process a single field if test_flag is True\n",
    "if test_flag:\n",
    "    print('processing a single field')\n",
    "    df_huc = df_huc.loc[df_huc.index == 'ORx_155121']\n",
    "    df_c_pre = df_c_pre.loc[df_c_pre.index == 'ORx_155121']\n",
    "    df_typ = df_typ.loc[df_typ.index == 'ORx_155121']\n",
    "    df_cue = df_cue.loc[df_cue.index == 'ORx_155121']\n",
    "else:\n",
    "    print('processing all fields')\n",
    "\n",
    "\n",
    "# loop through each year\n",
    "for year in year_list:\n",
    "    \n",
    "    # ET dataframe\n",
    "    df_et = pd.read_csv(os.path.join(table_path, f'or_field_summaries_water_year_shift_1mo_{year}_et.csv'), index_col='OPENET_ID')\n",
    "\n",
    "    # ET Fraction dataframe\n",
    "    df_etf = pd.read_csv(os.path.join(table_path, f'or_field_summaries_water_year_shift_1mo_{year}_et_fraction.csv'), index_col='OPENET_ID')\n",
    "        \n",
    "    # ET Reference dataframe\n",
    "    df_eto = pd.read_csv(os.path.join(table_path, f'or_field_summaries_water_year_shift_1mo_{year}_et_reference.csv'),index_col='OPENET_ID')\n",
    "\n",
    "    # Crop Type and gridmet ID dataframe\n",
    "    df_c = df_c_pre[[f'CROP_{year}', 'GRIDMET_ID']]\n",
    "\n",
    "    # precip dataframe\n",
    "    df_ppt = pd.read_csv(os.path.join(table_path, f'or_field_summaries_water_year_shift_1mo_{year}_ppt.csv'), index_col='OPENET_ID') \n",
    "        \n",
    "    # IrrMapper Irrigated dataframe\n",
    "    df_irr = pd.read_csv(os.path.join(table_path, f'or_field_summaries_{year}_irrmapper_irrigated.csv'), index_col='OPENET_ID')\n",
    "    df_irr[f'%_IRRIGATED_{str(year)[2:]}'] = (df_irr['ACRES_IRRIGATED'] / df_irr['ACRES_ALL']) * 100\n",
    "\n",
    "    # IrrMapper Wetland dataframe\n",
    "    df_wtl = pd.read_csv(os.path.join(table_path, f'or_field_summaries_{year}_irrmapper_wetland.csv'), index_col='OPENET_ID')\n",
    "    df_wtl[f'%_WETLAND_{str(year)[2:]}'] = (df_wtl['ACRES_WETLAND'] / df_wtl['ACRES_ALL']) * 100\n",
    "    df_wtl = df_wtl.drop(columns=['ACRES_ALL'])\n",
    "\n",
    "    # EToF irrigation status dataframe\n",
    "    df_etof_irr_status = pd.read_csv(os.path.join(table_path, f'or_field_summaries_{year}_etof_irr_status.csv'), index_col='OPENET_ID')\n",
    "\n",
    "    # unclassified field nans need to be filled with code 5 for filtering (they are assumed irrigated since they are usually small polygons for single home lawns)\n",
    "    df_etof_irr_status[f'ETOF_IRR_STATUS_{str(year)[2:]}_MODE'] =  df_etof_irr_status[f'ETOF_IRR_STATUS_{str(year)[2:]}_MODE'].fillna(5)\n",
    "\n",
    "    # concatenate dataframes on columns using index (unique ID) to match fields\n",
    "    df = pd.concat([df_huc, df_cue, df_typ, df_c, df_irr, df_wtl, df_etof_irr_status, df_et, df_etf, df_eto, df_ppt], axis=1)\n",
    "\n",
    "    # filter out bad geometries\n",
    "    df = df.loc[~df.index.isin(bad_list)]\n",
    "    \n",
    "    # reset the index\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # export joined dataframe for pairing with ET Demands\n",
    "    df.to_csv(os.path.join(out_path, f'or_field_summaries_water_year_shift_1mo_{year}_pre_et_demands.csv'), index=False)\n",
    "        \n",
    "    print(f'exported dataframe for {year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7becca4b-701d-46a4-8936-913f1f416d5c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Join ET Demands data to field summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b4621-6b57-4b3a-82ff-f419ebc281be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# list of years based on start/end parameters\n",
    "year_list = list(range(start_year, end_year+1))\n",
    "\n",
    "# CDL - ET Demands crosswalk file\n",
    "in_path = table_path.replace('ee_exports', 'post_processing\\\\2_for_et_demands_join')\n",
    "\n",
    "# ET Demands monthly data path\n",
    "etd_path = table_path.replace('ee_exports', 'post_processing\\\\2_for_et_demands_join\\\\et_demands')\n",
    "\n",
    "# output path\n",
    "out_path = table_path.replace('ee_exports', 'post_processing\\\\3_pre_gap_filled')\n",
    "\n",
    "# prepare dictionary of crop type codes from CDL and ET Demands\n",
    "cross_df = pd.read_csv(os.path.join(in_path, 'OR_unique_cdl_etdemands_crosswalk_model_setup.csv'))\n",
    "cross_dict = dict()\n",
    "for index, row in cross_df.iterrows():\n",
    "    cross_dict[row.cdl_no] = list(map(int, str(row.etd_no).split(',')))\n",
    "\n",
    "    \n",
    "# function to filter the filenames down to the model we are analyzing\n",
    "def Filter(string, substr):\n",
    "    return [str for str in string if\n",
    "             any(sub in str for sub in substr)]\n",
    "\n",
    "# loop through each year in the specified list\n",
    "for year in year_list:\n",
    "\n",
    "    # monthly openet composite dataframe (each column is monthly value)\n",
    "    df_et = pd.read_csv(os.path.join(in_path, f'or_field_summaries_water_year_shift_1mo_{year}_pre_et_demands.csv'), index_col='OPENET_ID')\n",
    "\n",
    "    # create empty columns to fill\n",
    "    df_et[f'ETD_{str(year)[2:]}'] = np.nan\n",
    "\n",
    "    df_et[f'ETDa_11_{str(year-1)[2:]}'] = np.nan\n",
    "    df_et[f'ETDa_12_{str(year-1)[2:]}'] = np.nan\n",
    "    df_et[f'ETDa_01_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'ETDa_02_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'ETDa_03_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'ETDa_04_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'ETDa_05_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'ETDa_06_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'ETDa_07_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'ETDa_08_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'ETDa_09_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'ETDa_10_{str(year)[2:]}'] = np.nan\n",
    "\n",
    "    # df_et[f'P_eft_11_{str(year-1)[2:]}'] = np.nan\n",
    "    # df_et[f'P_eft_12_{str(year-1)[2:]}'] = np.nan \n",
    "    # df_et[f'P_eft_01_{str(year)[2:]}'] = np.nan\n",
    "    # df_et[f'P_eft_02_{str(year)[2:]}'] = np.nan\n",
    "    # df_et[f'P_eft_03_{str(year)[2:]}'] = np.nan\n",
    "    # df_et[f'P_eft_04_{str(year)[2:]}'] = np.nan\n",
    "    # df_et[f'P_eft_05_{str(year)[2:]}'] = np.nan\n",
    "    # df_et[f'P_eft_06_{str(year)[2:]}'] = np.nan\n",
    "    # df_et[f'P_eft_07_{str(year)[2:]}'] = np.nan\n",
    "    # df_et[f'P_eft_08_{str(year)[2:]}'] = np.nan\n",
    "    # df_et[f'P_eft_09_{str(year)[2:]}'] = np.nan\n",
    "    # df_et[f'P_eft_10_{str(year)[2:]}'] = np.nan\n",
    "    \n",
    "    df_et[f'P_rz_11_{str(year-1)[2:]}'] = np.nan\n",
    "    df_et[f'P_rz_12_{str(year-1)[2:]}'] = np.nan \n",
    "    df_et[f'P_rz_01_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'P_rz_02_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'P_rz_03_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'P_rz_04_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'P_rz_05_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'P_rz_06_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'P_rz_07_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'P_rz_08_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'P_rz_09_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'P_rz_10_{str(year)[2:]}'] = np.nan\n",
    "\n",
    "    df_et[f'NIWR_11_{str(year-1)[2:]}'] = np.nan\n",
    "    df_et[f'NIWR_12_{str(year-1)[2:]}'] = np.nan     \n",
    "    df_et[f'NIWR_01_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'NIWR_02_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'NIWR_03_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'NIWR_04_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'NIWR_05_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'NIWR_06_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'NIWR_07_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'NIWR_08_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'NIWR_09_{str(year)[2:]}'] = np.nan\n",
    "    df_et[f'NIWR_10_{str(year)[2:]}'] = np.nan\n",
    "\n",
    "    for row in df_et.itertuples():\n",
    "\n",
    "        # crop type for specified year used for crosswalking to ET Demands codes\n",
    "        cdl_c = df_et[f'CROP_{year}'].at[row.Index]\n",
    "    \n",
    "        # gridmet cell ID\n",
    "        grid_id = int(df_et['GRIDMET_ID'].at[row.Index])\n",
    "        \n",
    "        # ET Demands crosswalk value for CDL code\n",
    "        try:\n",
    "            etd_c_int = cross_dict[cdl_c][0]\n",
    "        except Exception as e:\n",
    "            print(row)\n",
    "            print(e)\n",
    "            continue\n",
    "        etd_c = str(etd_c_int).zfill(2)\n",
    "        \n",
    "\n",
    "        # read ET Demands file using gridMET ID and crop type \n",
    "        filename = f'{grid_id}_crop_{etd_c}.csv'\n",
    "\n",
    "        # use these lines instead of the try/except to check if an ET Demands file is missing\n",
    "        # if os.path.isfile(os.path.join(etd_dir, filename)):\n",
    "        #     continue\n",
    "        # else:\n",
    "        #     print(f'Missing: {filename}')\n",
    "        #     continue\n",
    "        \n",
    "        try:\n",
    "            df_etd = pd.read_csv(os.path.join(etd_path, filename), header=1, index_col='Date', parse_dates=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Missing: {filename}')\n",
    "            # print(e)\n",
    "            continue\n",
    "\n",
    "        # filter df to specified year\n",
    "        df_etd_f = df_etd[df_etd['Year'].isin([(year-1), year])]\n",
    "\n",
    "        df_et[f'ETD_{str(year)[2:]}'].at[row.Index] = etd_c\n",
    "        \n",
    "        df_et[f'ETDa_11_{str(year-1)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 11) & (df_etd_f['Year'] == (year-1))]['ETact'].iloc[0]\n",
    "        df_et[f'ETDa_12_{str(year-1)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 12) & (df_etd_f['Year'] == (year-1))]['ETact'].iloc[0]\n",
    "        df_et[f'ETDa_01_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 1) & (df_etd_f['Year'] == year)]['ETact'].iloc[0]\n",
    "        df_et[f'ETDa_02_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 2) & (df_etd_f['Year'] == year)]['ETact'].iloc[0]\n",
    "        df_et[f'ETDa_03_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 3) & (df_etd_f['Year'] == year)]['ETact'].iloc[0]\n",
    "        df_et[f'ETDa_04_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 4) & (df_etd_f['Year'] == year)]['ETact'].iloc[0]\n",
    "        df_et[f'ETDa_05_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 5) & (df_etd_f['Year'] == year)]['ETact'].iloc[0]\n",
    "        df_et[f'ETDa_06_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 6) & (df_etd_f['Year'] == year)]['ETact'].iloc[0]\n",
    "        df_et[f'ETDa_07_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 7) & (df_etd_f['Year'] == year)]['ETact'].iloc[0]\n",
    "        df_et[f'ETDa_08_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 8) & (df_etd_f['Year'] == year)]['ETact'].iloc[0]\n",
    "        df_et[f'ETDa_09_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 9) & (df_etd_f['Year'] == year)]['ETact'].iloc[0]\n",
    "        df_et[f'ETDa_10_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 10) & (df_etd_f['Year'] == year)]['ETact'].iloc[0]\n",
    "\n",
    "        # df_et[f'P_eft_11_{str(year-1)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 11) & (df_etd_f['Year'] == (year-1))]['P_eft'].iloc[0]\n",
    "        # df_et[f'P_eft_12_{str(year-1)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 12) & (df_etd_f['Year'] == (year-1))]['P_eft'].iloc[0]\n",
    "        # df_et[f'P_eft_01_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 1) & (df_etd_f['Year'] == year)]['P_eft'].iloc[0]\n",
    "        # df_et[f'P_eft_02_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 2) & (df_etd_f['Year'] == year)]['P_eft'].iloc[0]\n",
    "        # df_et[f'P_eft_03_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 3) & (df_etd_f['Year'] == year)]['P_eft'].iloc[0]\n",
    "        # df_et[f'P_eft_04_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 4) & (df_etd_f['Year'] == year)]['P_eft'].iloc[0]\n",
    "        # df_et[f'P_eft_05_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 5) & (df_etd_f['Year'] == year)]['P_eft'].iloc[0]\n",
    "        # df_et[f'P_eft_06_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 6) & (df_etd_f['Year'] == year)]['P_eft'].iloc[0]\n",
    "        # df_et[f'P_eft_07_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 7) & (df_etd_f['Year'] == year)]['P_eft'].iloc[0]\n",
    "        # df_et[f'P_eft_08_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 8) & (df_etd_f['Year'] == year)]['P_eft'].iloc[0]\n",
    "        # df_et[f'P_eft_09_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 9) & (df_etd_f['Year'] == year)]['P_eft'].iloc[0]\n",
    "        # df_et[f'P_eft_10_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 10) & (df_etd_f['Year'] == year)]['P_eft'].iloc[0]\n",
    "\n",
    "        df_et[f'P_rz_11_{str(year-1)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 11) & (df_etd_f['Year'] == (year-1))]['P_rz'].iloc[0]\n",
    "        df_et[f'P_rz_12_{str(year-1)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 12) & (df_etd_f['Year'] == (year-1))]['P_rz'].iloc[0]\n",
    "        df_et[f'P_rz_01_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 1) & (df_etd_f['Year'] == year)]['P_rz'].iloc[0]\n",
    "        df_et[f'P_rz_02_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 2) & (df_etd_f['Year'] == year)]['P_rz'].iloc[0]\n",
    "        df_et[f'P_rz_03_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 3) & (df_etd_f['Year'] == year)]['P_rz'].iloc[0]\n",
    "        df_et[f'P_rz_04_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 4) & (df_etd_f['Year'] == year)]['P_rz'].iloc[0]\n",
    "        df_et[f'P_rz_05_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 5) & (df_etd_f['Year'] == year)]['P_rz'].iloc[0]\n",
    "        df_et[f'P_rz_06_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 6) & (df_etd_f['Year'] == year)]['P_rz'].iloc[0]\n",
    "        df_et[f'P_rz_07_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 7) & (df_etd_f['Year'] == year)]['P_rz'].iloc[0]\n",
    "        df_et[f'P_rz_08_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 8) & (df_etd_f['Year'] == year)]['P_rz'].iloc[0]\n",
    "        df_et[f'P_rz_09_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 9) & (df_etd_f['Year'] == year)]['P_rz'].iloc[0]\n",
    "        df_et[f'P_rz_10_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 10) & (df_etd_f['Year'] == year)]['P_rz'].iloc[0]\n",
    "\n",
    "        df_et[f'NIWR_11_{str(year-1)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 11) & (df_etd_f['Year'] == (year-1))]['NIWR'].iloc[0]\n",
    "        df_et[f'NIWR_12_{str(year-1)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 12) & (df_etd_f['Year'] == (year-1))]['NIWR'].iloc[0]\n",
    "        df_et[f'NIWR_01_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 1) & (df_etd_f['Year'] == year)]['NIWR'].iloc[0]\n",
    "        df_et[f'NIWR_02_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 2) & (df_etd_f['Year'] == year)]['NIWR'].iloc[0]\n",
    "        df_et[f'NIWR_03_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 3) & (df_etd_f['Year'] == year)]['NIWR'].iloc[0]\n",
    "        df_et[f'NIWR_04_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 4) & (df_etd_f['Year'] == year)]['NIWR'].iloc[0]\n",
    "        df_et[f'NIWR_05_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 5) & (df_etd_f['Year'] == year)]['NIWR'].iloc[0]\n",
    "        df_et[f'NIWR_06_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 6) & (df_etd_f['Year'] == year)]['NIWR'].iloc[0]\n",
    "        df_et[f'NIWR_07_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 7) & (df_etd_f['Year'] == year)]['NIWR'].iloc[0]\n",
    "        df_et[f'NIWR_08_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 8) & (df_etd_f['Year'] == year)]['NIWR'].iloc[0]\n",
    "        df_et[f'NIWR_09_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 9) & (df_etd_f['Year'] == year)]['NIWR'].iloc[0]\n",
    "        df_et[f'NIWR_10_{str(year)[2:]}'].at[row.Index] = df_etd_f.loc[(df_etd_f['Month'] == 10) & (df_etd_f['Year'] == year)]['NIWR'].iloc[0]\n",
    "\n",
    "    df_et.to_csv(os.path.join(out_path, f'or_openet_etdemands_monthly_water_year_shift_1mo_{year}_pre_gapfill.csv'))\n",
    "    \n",
    "    print(f'finished processing all files for {year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f35723-2de1-4b4f-b636-1f9fd057f54d",
   "metadata": {},
   "source": [
    "## 3. Gap-fill EToF using linear interpolation (1 mo) or climatologies (2+ mo)\n",
    "\n",
    "* Start/End Year Options:\n",
    "> 1985-1991<br>\n",
    "> 1992-1997<br>\n",
    "> 1998-2003<br>\n",
    "> 2004-2009<br>\n",
    "> 2010-2015<br>\n",
    "> 2016-2022<br>\n",
    "\n",
    "\n",
    "### NOTE: This step requires all individual annual tables within the respective gap-filling window to be processed in the previous step (i.e., ET Demands join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e58fdd7-c706-4b2b-b14f-b250acc535e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yr_list = np.arange(start_year, end_year+1)\n",
    "yr_abr_list = [int(str(yr)[2:]) for yr in yr_list]\n",
    "\n",
    "eff_ppt_var = 'P_rz'\n",
    "\n",
    "# input path\n",
    "in_path = table_path.replace('ee_exports', 'post_processing\\\\3_pre_gap_filled')\n",
    "\n",
    "# output path\n",
    "out_path = table_path.replace('ee_exports', 'post_processing\\\\4_gap_filled')\n",
    "\n",
    "# EToF Climatology  dataframe to gap-fill if multiple adjacent-months missing (also first and last values)\n",
    "if (yr_list[0] == 1985 and yr_list[-1] == 1991):\n",
    "    df_c = pd.read_csv(os.path.join(table_path, f'or_field_summaries_water_year_shift_1mo_1984_{yr_list[-1]}_et_fraction_climo.csv'), index_col='OPENET_ID')\n",
    "elif (yr_list[0] == 2016 and yr_list[-1] == 2022):\n",
    "    df_c = pd.read_csv(os.path.join(table_path, f'or_field_summaries_water_year_shift_1mo_{yr_list[0]}_2021_et_fraction_climo.csv'), index_col='OPENET_ID')\n",
    "else:\n",
    "    df_c = pd.read_csv(os.path.join(table_path, f'or_field_summaries_water_year_shift_1mo_{yr_list[0]}_{yr_list[-1]}_et_fraction_climo.csv'), index_col='OPENET_ID')\n",
    "\n",
    "# rename columns for climo file\n",
    "df_c.columns = ['ETc_Fraction_11','ETc_Fraction_12','ETc_Fraction_01','ETc_Fraction_02','ETc_Fraction_03','ETc_Fraction_04','ETc_Fraction_05','ETc_Fraction_06',\n",
    "                'ETc_Fraction_07','ETc_Fraction_08','ETc_Fraction_09','ETc_Fraction_10']\n",
    "\n",
    "# read all years into dataframes in order to concatenate and gap fill properly\n",
    "if (yr_list[0] == 1985 and yr_list[-1] == 1991):\n",
    "    df1 = pd.read_csv(os.path.join(in_path, 'or_openet_etdemands_monthly_water_year_shift_1mo_1985_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df1 = df1.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[0]:02d}'})\n",
    "    df2 = pd.read_csv(os.path.join(in_path, 'or_openet_etdemands_monthly_water_year_shift_1mo_1986_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df2 = df2.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[1]:02d}'})\n",
    "    df3 = pd.read_csv(os.path.join(in_path, 'or_openet_etdemands_monthly_water_year_shift_1mo_1987_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df3 = df3.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[2]:02d}'})\n",
    "    df4 = pd.read_csv(os.path.join(in_path, 'or_openet_etdemands_monthly_water_year_shift_1mo_1988_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df4 = df4.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[3]:02d}'})\n",
    "    df5 = pd.read_csv(os.path.join(in_path, 'or_openet_etdemands_monthly_water_year_shift_1mo_1989_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df5 = df5.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[4]:02d}'})\n",
    "    df6 = pd.read_csv(os.path.join(in_path, 'or_openet_etdemands_monthly_water_year_shift_1mo_1990_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df6 = df6.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[5]:02d}'})\n",
    "    df7 = pd.read_csv(os.path.join(in_path, 'or_openet_etdemands_monthly_water_year_shift_1mo_1991_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df7 = df7.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[6]:02d}'})\n",
    "\n",
    "    df = pd.concat([df_c, df1, df2, df3, df4, df5, df6, df7], axis=1)\n",
    "elif (yr_list[0] == 2016 and yr_list[-1] == 2022):\n",
    "    df1 = pd.read_csv(os.path.join(in_path, 'or_openet_etdemands_monthly_water_year_shift_1mo_2016_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df1 = df1.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[0]:02d}'})\n",
    "    df2 = pd.read_csv(os.path.join(in_path, 'or_openet_etdemands_monthly_water_year_shift_1mo_2017_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df2 = df2.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[1]:02d}'})\n",
    "    df3 = pd.read_csv(os.path.join(in_path, 'or_openet_etdemands_monthly_water_year_shift_1mo_2018_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df3 = df3.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[2]:02d}'})\n",
    "    df4 = pd.read_csv(os.path.join(in_path, 'or_openet_etdemands_monthly_water_year_shift_1mo_2019_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df4 = df4.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[3]:02d}'})\n",
    "    df5 = pd.read_csv(os.path.join(in_path, 'or_openet_etdemands_monthly_water_year_shift_1mo_2020_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df5 = df5.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[4]:02d}'})\n",
    "    df6 = pd.read_csv(os.path.join(in_path, 'or_openet_etdemands_monthly_water_year_shift_1mo_2021_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df6 = df6.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[5]:02d}'})\n",
    "    df7 = pd.read_csv(os.path.join(in_path, 'or_openet_etdemands_monthly_water_year_shift_1mo_2022_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df7 = df7.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[6]:02d}'})\n",
    "\n",
    "    df = pd.concat([df_c, df1, df2, df3, df4, df5, df6, df7], axis=1)\n",
    "else:\n",
    "    df1 = pd.read_csv(os.path.join(main_dir, f'or_openet_etdemands_monthly_water_year_shift_1mo_{yr_list[0]}_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df1 = df1.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[0]:02d}'})\n",
    "    df2 = pd.read_csv(os.path.join(main_dir, f'or_openet_etdemands_monthly_water_year_shift_1mo_{yr_list[1]}_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df2 = df2.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[1]:02d}'})\n",
    "    df3 = pd.read_csv(os.path.join(main_dir, f'or_openet_etdemands_monthly_water_year_shift_1mo_{yr_list[2]}_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df3 = df3.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[2]:02d}'})\n",
    "    df4 = pd.read_csv(os.path.join(main_dir, f'or_openet_etdemands_monthly_water_year_shift_1mo_{yr_list[3]}_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df4 = df4.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[3]:02d}'})\n",
    "    df5 = pd.read_csv(os.path.join(main_dir, f'or_openet_etdemands_monthly_water_year_shift_1mo_{yr_list[4]}_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df5 = df5.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[4]:02d}'})\n",
    "    df6 = pd.read_csv(os.path.join(main_dir, f'or_openet_etdemands_monthly_water_year_shift_1mo_{yr_list[5]}_pre_gapfill.csv'), index_col='OPENET_ID')\n",
    "    df6 = df6.rename(columns={'ACRES_FTR_GEOM': f'ACRES_FTR_GEOM_{yr_abr_list[5]:02d}'})\n",
    "\n",
    "    df = pd.concat([df_c, df1, df2, df3, df4, df5, df6], axis=1)\n",
    "\n",
    "# Last month of period needs to be filled with climo before linear interpolation (first month does not since interp doesn't catch it)\n",
    "df[f'ET_Fraction_10_{yr_abr_list[-1]:02d}'] = df[f'ET_Fraction_10_{yr_abr_list[-1]:02d}'].fillna(df['ETc_Fraction_10'])\n",
    "\n",
    "# linearly interpolate isolated monthly nans/gaps \n",
    "# df_t = df.loc[:,df.columns.str.contains('ET_Fraction')]\n",
    "# df.loc[:,df.columns.str.contains('ET_Fraction')] = df.loc[:,df.columns.str.contains('ET_Fraction')].interpolate(method='linear',limit=1,limit_area='inside',axis=1)\n",
    "\n",
    "# linearly interpolate isolated monthly nans/gaps only, not consecutive nans\n",
    "fval = (df.loc[:, df.columns.str.contains('ET_Fraction')].shift(1, axis=1).add(df.loc[:, df.columns.str.contains('ET_Fraction')].shift(-1, axis=1)) / 2)\n",
    "df.loc[:, df.columns.str.contains('ET_Fraction')] = df.loc[:, df.columns.str.contains('ET_Fraction')].fillna(value=fval, axis=1)\n",
    "\n",
    "# fill non-isolated (i.e., consecutive/adjacent) monthly nans/gaps with the climo values explicitly\n",
    "for yr in yr_abr_list:\n",
    "    print(f'gap filling {yr}')\n",
    "\n",
    "    # fill the rest of the nans (consecutive nans) with the climatologies\n",
    "    # the year 2000 has to have this special condition for subtracting 1 from 0 (2000 actual year value)\n",
    "    if yr == 0:\n",
    "        df['ET_Fraction_11_99'] = df['ET_Fraction_11_99'].fillna(df['ETc_Fraction_11'])\n",
    "        df['ET_Fraction_12_99'] = df['ET_Fraction_12_99'].fillna(df['ETc_Fraction_12'])\n",
    "    else:\n",
    "        df[f'ET_Fraction_11_{yr-1:02d}'] = df[f'ET_Fraction_11_{yr-1:02d}'].fillna(df['ETc_Fraction_11'])\n",
    "        df[f'ET_Fraction_12_{yr-1:02d}'] = df[f'ET_Fraction_12_{yr-1:02d}'].fillna(df['ETc_Fraction_12'])\n",
    "    df[f'ET_Fraction_01_{yr:02d}'] = df[f'ET_Fraction_01_{yr:02d}'].fillna(df['ETc_Fraction_01'])\n",
    "    df[f'ET_Fraction_02_{yr:02d}'] = df[f'ET_Fraction_02_{yr:02d}'].fillna(df['ETc_Fraction_02'])\n",
    "    df[f'ET_Fraction_03_{yr:02d}'] = df[f'ET_Fraction_03_{yr:02d}'].fillna(df['ETc_Fraction_03'])\n",
    "    df[f'ET_Fraction_04_{yr:02d}'] = df[f'ET_Fraction_04_{yr:02d}'].fillna(df['ETc_Fraction_04'])\n",
    "    df[f'ET_Fraction_05_{yr:02d}'] = df[f'ET_Fraction_05_{yr:02d}'].fillna(df['ETc_Fraction_05'])\n",
    "    df[f'ET_Fraction_06_{yr:02d}'] = df[f'ET_Fraction_06_{yr:02d}'].fillna(df['ETc_Fraction_06'])\n",
    "    df[f'ET_Fraction_07_{yr:02d}'] = df[f'ET_Fraction_07_{yr:02d}'].fillna(df['ETc_Fraction_07'])\n",
    "    df[f'ET_Fraction_08_{yr:02d}'] = df[f'ET_Fraction_08_{yr:02d}'].fillna(df['ETc_Fraction_08'])\n",
    "    df[f'ET_Fraction_09_{yr:02d}'] = df[f'ET_Fraction_09_{yr:02d}'].fillna(df['ETc_Fraction_09'])\n",
    "    df[f'ET_Fraction_10_{yr:02d}'] = df[f'ET_Fraction_10_{yr:02d}'].fillna(df['ETc_Fraction_10'])\n",
    "\n",
    "    # some fields' EToF climos for Dec 1984 were missing so need to interpolate those months after above gap-filling\n",
    "    if yr == 85:\n",
    "        df.loc[:,df.columns.str.contains('ET_Fraction')] = df.loc[:,df.columns.str.contains('ET_Fraction')].interpolate(method='linear', axis=1)        \n",
    "\n",
    "    # fill nans in actual et with the gap-filled et fraction * et reference\n",
    "    if yr == 0:\n",
    "        df[f'ETa_11_99'] = df[f'ETa_11_99'].fillna(df[f'ET_Fraction_11_99'] * df[f'ET_Reference_11_99'])\n",
    "        df[f'ETa_12_99'] = df[f'ETa_12_99'].fillna(df[f'ET_Fraction_12_99'] * df[f'ET_Reference_12_99'])\n",
    "    else:  \n",
    "        df[f'ETa_11_{yr-1:02d}'] = df[f'ETa_11_{yr-1:02d}'].fillna(df[f'ET_Fraction_11_{yr-1:02d}'] * df[f'ET_Reference_11_{yr-1:02d}'])\n",
    "        df[f'ETa_12_{yr-1:02d}'] = df[f'ETa_12_{yr-1:02d}'].fillna(df[f'ET_Fraction_12_{yr-1:02d}'] * df[f'ET_Reference_12_{yr-1:02d}'])\n",
    "    df[f'ETa_01_{yr:02d}'] = df[f'ETa_01_{yr:02d}'].fillna(df[f'ET_Fraction_01_{yr:02d}'] * df[f'ET_Reference_01_{yr:02d}'])\n",
    "    df[f'ETa_02_{yr:02d}'] = df[f'ETa_02_{yr:02d}'].fillna(df[f'ET_Fraction_02_{yr:02d}'] * df[f'ET_Reference_02_{yr:02d}'])\n",
    "    df[f'ETa_03_{yr:02d}'] = df[f'ETa_03_{yr:02d}'].fillna(df[f'ET_Fraction_03_{yr:02d}'] * df[f'ET_Reference_03_{yr:02d}'])\n",
    "    df[f'ETa_04_{yr:02d}'] = df[f'ETa_04_{yr:02d}'].fillna(df[f'ET_Fraction_04_{yr:02d}'] * df[f'ET_Reference_04_{yr:02d}'])\n",
    "    df[f'ETa_05_{yr:02d}'] = df[f'ETa_05_{yr:02d}'].fillna(df[f'ET_Fraction_05_{yr:02d}'] * df[f'ET_Reference_05_{yr:02d}'])\n",
    "    df[f'ETa_06_{yr:02d}'] = df[f'ETa_06_{yr:02d}'].fillna(df[f'ET_Fraction_06_{yr:02d}'] * df[f'ET_Reference_06_{yr:02d}'])\n",
    "    df[f'ETa_07_{yr:02d}'] = df[f'ETa_07_{yr:02d}'].fillna(df[f'ET_Fraction_07_{yr:02d}'] * df[f'ET_Reference_07_{yr:02d}'])\n",
    "    df[f'ETa_08_{yr:02d}'] = df[f'ETa_08_{yr:02d}'].fillna(df[f'ET_Fraction_08_{yr:02d}'] * df[f'ET_Reference_08_{yr:02d}'])\n",
    "    df[f'ETa_09_{yr:02d}'] = df[f'ETa_09_{yr:02d}'].fillna(df[f'ET_Fraction_09_{yr:02d}'] * df[f'ET_Reference_09_{yr:02d}'])\n",
    "    df[f'ETa_10_{yr:02d}'] = df[f'ETa_10_{yr:02d}'].fillna(df[f'ET_Fraction_10_{yr:02d}'] * df[f'ET_Reference_10_{yr:02d}'])\n",
    "    \n",
    "    # convert units from mm to inches \n",
    "    if yr == 0:\n",
    "        df[f'ETa_11_99_in'] = df[f'ETa_11_99'] / 25.4\n",
    "        df[f'ETa_12_99_in'] = df[f'ETa_12_99'] / 25.4\n",
    "    else:\n",
    "        df[f'ETa_11_{yr-1:02d}_in'] = df[f'ETa_11_{yr-1:02d}'] / 25.4\n",
    "        df[f'ETa_12_{yr-1:02d}_in'] = df[f'ETa_12_{yr-1:02d}'] / 25.4\n",
    "    df[f'ETa_01_{yr:02d}_in'] = df[f'ETa_01_{yr:02d}'] / 25.4\n",
    "    df[f'ETa_02_{yr:02d}_in'] = df[f'ETa_02_{yr:02d}'] / 25.4\n",
    "    df[f'ETa_03_{yr:02d}_in'] = df[f'ETa_03_{yr:02d}'] / 25.4\n",
    "    df[f'ETa_04_{yr:02d}_in'] = df[f'ETa_04_{yr:02d}'] / 25.4\n",
    "    df[f'ETa_05_{yr:02d}_in'] = df[f'ETa_05_{yr:02d}'] / 25.4\n",
    "    df[f'ETa_06_{yr:02d}_in'] = df[f'ETa_06_{yr:02d}'] / 25.4\n",
    "    df[f'ETa_07_{yr:02d}_in'] = df[f'ETa_07_{yr:02d}'] / 25.4\n",
    "    df[f'ETa_08_{yr:02d}_in'] = df[f'ETa_08_{yr:02d}'] / 25.4\n",
    "    df[f'ETa_09_{yr:02d}_in'] = df[f'ETa_09_{yr:02d}'] / 25.4\n",
    "    df[f'ETa_10_{yr:02d}_in'] = df[f'ETa_10_{yr:02d}'] / 25.4\n",
    "    \n",
    "    # convert units from mm to inches \n",
    "    if yr == 0:\n",
    "        df[f'ETDa_11_99_in'] = df[f'ETDa_11_99'] / 25.4\n",
    "        df[f'ETDa_12_99_in'] = df[f'ETDa_12_99'] / 25.4\n",
    "    else:\n",
    "        df[f'ETDa_11_{yr-1:02d}_in'] = df[f'ETDa_11_{yr-1:02d}'] / 25.4\n",
    "        df[f'ETDa_12_{yr-1:02d}_in'] = df[f'ETDa_12_{yr-1:02d}'] / 25.4\n",
    "    df[f'ETDa_01_{yr:02d}_in'] = df[f'ETDa_01_{yr:02d}'] / 25.4\n",
    "    df[f'ETDa_02_{yr:02d}_in'] = df[f'ETDa_02_{yr:02d}'] / 25.4\n",
    "    df[f'ETDa_03_{yr:02d}_in'] = df[f'ETDa_03_{yr:02d}'] / 25.4\n",
    "    df[f'ETDa_04_{yr:02d}_in'] = df[f'ETDa_04_{yr:02d}'] / 25.4\n",
    "    df[f'ETDa_05_{yr:02d}_in'] = df[f'ETDa_05_{yr:02d}'] / 25.4\n",
    "    df[f'ETDa_06_{yr:02d}_in'] = df[f'ETDa_06_{yr:02d}'] / 25.4\n",
    "    df[f'ETDa_07_{yr:02d}_in'] = df[f'ETDa_07_{yr:02d}'] / 25.4\n",
    "    df[f'ETDa_08_{yr:02d}_in'] = df[f'ETDa_08_{yr:02d}'] / 25.4\n",
    "    df[f'ETDa_09_{yr:02d}_in'] = df[f'ETDa_09_{yr:02d}'] / 25.4\n",
    "    df[f'ETDa_10_{yr:02d}_in'] = df[f'ETDa_10_{yr:02d}'] / 25.4\n",
    "\n",
    "    if yr == 0:\n",
    "        df[f'ET_Reference_11_99_in'] = df[f'ET_Reference_11_99'] / 25.4\n",
    "        df[f'ET_Reference_12_99_in'] = df[f'ET_Reference_12_99'] / 25.4\n",
    "    else:\n",
    "        df[f'ET_Reference_11_{yr-1:02d}_in'] = df[f'ET_Reference_11_{yr-1:02d}'] / 25.4\n",
    "        df[f'ET_Reference_12_{yr-1:02d}_in'] = df[f'ET_Reference_12_{yr-1:02d}'] / 25.4\n",
    "    df[f'ET_Reference_01_{yr:02d}_in'] = df[f'ET_Reference_01_{yr:02d}'] / 25.4\n",
    "    df[f'ET_Reference_02_{yr:02d}_in'] = df[f'ET_Reference_02_{yr:02d}'] / 25.4\n",
    "    df[f'ET_Reference_03_{yr:02d}_in'] = df[f'ET_Reference_03_{yr:02d}'] / 25.4\n",
    "    df[f'ET_Reference_04_{yr:02d}_in'] = df[f'ET_Reference_04_{yr:02d}'] / 25.4\n",
    "    df[f'ET_Reference_05_{yr:02d}_in'] = df[f'ET_Reference_05_{yr:02d}'] / 25.4\n",
    "    df[f'ET_Reference_06_{yr:02d}_in'] = df[f'ET_Reference_06_{yr:02d}'] / 25.4\n",
    "    df[f'ET_Reference_07_{yr:02d}_in'] = df[f'ET_Reference_07_{yr:02d}'] / 25.4\n",
    "    df[f'ET_Reference_08_{yr:02d}_in'] = df[f'ET_Reference_08_{yr:02d}'] / 25.4\n",
    "    df[f'ET_Reference_09_{yr:02d}_in'] = df[f'ET_Reference_09_{yr:02d}'] / 25.4\n",
    "    df[f'ET_Reference_10_{yr:02d}_in'] = df[f'ET_Reference_10_{yr:02d}'] / 25.4\n",
    "    \n",
    "    if yr == 0:\n",
    "        df[f'PPT_11_99_in'] = df[f'PPT_11_99'] / 25.4\n",
    "        df[f'PPT_12_99_in'] = df[f'PPT_12_99'] / 25.4\n",
    "    else:\n",
    "        df[f'PPT_11_{yr-1:02d}_in'] = df[f'PPT_11_{yr-1:02d}'] / 25.4\n",
    "        df[f'PPT_12_{yr-1:02d}_in'] = df[f'PPT_12_{yr-1:02d}'] / 25.4\n",
    "    df[f'PPT_01_{yr:02d}_in'] = df[f'PPT_01_{yr:02d}'] / 25.4\n",
    "    df[f'PPT_02_{yr:02d}_in'] = df[f'PPT_02_{yr:02d}'] / 25.4\n",
    "    df[f'PPT_03_{yr:02d}_in'] = df[f'PPT_03_{yr:02d}'] / 25.4\n",
    "    df[f'PPT_04_{yr:02d}_in'] = df[f'PPT_04_{yr:02d}'] / 25.4\n",
    "    df[f'PPT_05_{yr:02d}_in'] = df[f'PPT_05_{yr:02d}'] / 25.4\n",
    "    df[f'PPT_06_{yr:02d}_in'] = df[f'PPT_06_{yr:02d}'] / 25.4\n",
    "    df[f'PPT_07_{yr:02d}_in'] = df[f'PPT_07_{yr:02d}'] / 25.4\n",
    "    df[f'PPT_08_{yr:02d}_in'] = df[f'PPT_08_{yr:02d}'] / 25.4\n",
    "    df[f'PPT_09_{yr:02d}_in'] = df[f'PPT_09_{yr:02d}'] / 25.4\n",
    "    df[f'PPT_10_{yr:02d}_in'] = df[f'PPT_10_{yr:02d}'] / 25.4\n",
    "    \n",
    "    # if yr == 0:\n",
    "    #     df[f'P_eft_11_99_in'] = df[f'P_eft_11_99'] / 25.4\n",
    "    #     df[f'P_eft_12_99_in'] = df[f'P_eft_12_99'] / 25.4    \n",
    "    # else:\n",
    "    #     df[f'P_eft_11_{yr-1:02d}_in'] = df[f'P_eft_11_{yr-1:02d}'] / 25.4\n",
    "    #     df[f'P_eft_12_{yr-1:02d}_in'] = df[f'P_eft_12_{yr-1:02d}'] / 25.4\n",
    "    # df[f'P_eft_01_{yr:02d}_in'] = df[f'P_eft_01_{yr:02d}'] / 25.4\n",
    "    # df[f'P_eft_02_{yr:02d}_in'] = df[f'P_eft_02_{yr:02d}'] / 25.4\n",
    "    # df[f'P_eft_03_{yr:02d}_in'] = df[f'P_eft_03_{yr:02d}'] / 25.4\n",
    "    # df[f'P_eft_04_{yr:02d}_in'] = df[f'P_eft_04_{yr:02d}'] / 25.4\n",
    "    # df[f'P_eft_05_{yr:02d}_in'] = df[f'P_eft_05_{yr:02d}'] / 25.4\n",
    "    # df[f'P_eft_06_{yr:02d}_in'] = df[f'P_eft_06_{yr:02d}'] / 25.4\n",
    "    # df[f'P_eft_07_{yr:02d}_in'] = df[f'P_eft_07_{yr:02d}'] / 25.4\n",
    "    # df[f'P_eft_08_{yr:02d}_in'] = df[f'P_eft_08_{yr:02d}'] / 25.4\n",
    "    # df[f'P_eft_09_{yr:02d}_in'] = df[f'P_eft_09_{yr:02d}'] / 25.4\n",
    "    # df[f'P_eft_10_{yr:02d}_in'] = df[f'P_eft_10_{yr:02d}'] / 25.4\n",
    "\n",
    "    if yr == 0:\n",
    "        df[f'P_rz_11_99_in'] = df[f'P_rz_11_99'] / 25.4\n",
    "        df[f'P_rz_12_99_in'] = df[f'P_rz_12_99'] / 25.4  \n",
    "    else:\n",
    "        df[f'P_rz_11_{yr-1:02d}_in'] = df[f'P_rz_11_{yr-1:02d}'] / 25.4\n",
    "        df[f'P_rz_12_{yr-1:02d}_in'] = df[f'P_rz_12_{yr-1:02d}'] / 25.4\n",
    "    df[f'P_rz_01_{yr:02d}_in'] = df[f'P_rz_01_{yr:02d}'] / 25.4\n",
    "    df[f'P_rz_02_{yr:02d}_in'] = df[f'P_rz_02_{yr:02d}'] / 25.4\n",
    "    df[f'P_rz_03_{yr:02d}_in'] = df[f'P_rz_03_{yr:02d}'] / 25.4\n",
    "    df[f'P_rz_04_{yr:02d}_in'] = df[f'P_rz_04_{yr:02d}'] / 25.4\n",
    "    df[f'P_rz_05_{yr:02d}_in'] = df[f'P_rz_05_{yr:02d}'] / 25.4\n",
    "    df[f'P_rz_06_{yr:02d}_in'] = df[f'P_rz_06_{yr:02d}'] / 25.4\n",
    "    df[f'P_rz_07_{yr:02d}_in'] = df[f'P_rz_07_{yr:02d}'] / 25.4\n",
    "    df[f'P_rz_08_{yr:02d}_in'] = df[f'P_rz_08_{yr:02d}'] / 25.4\n",
    "    df[f'P_rz_09_{yr:02d}_in'] = df[f'P_rz_09_{yr:02d}'] / 25.4\n",
    "    df[f'P_rz_10_{yr:02d}_in'] = df[f'P_rz_10_{yr:02d}'] / 25.4\n",
    "\n",
    "    if yr == 0:\n",
    "        df[f'NIWR_11_99_in'] = (df[f'NIWR_11_99'] / 25.4)\n",
    "        df[f'NIWR_12_99_in'] = (df[f'NIWR_12_99'] / 25.4)\n",
    "    else:\n",
    "        df[f'NIWR_11_{yr-1:02d}_in'] = (df[f'NIWR_11_{yr-1:02d}'] / 25.4)\n",
    "        df[f'NIWR_12_{yr-1:02d}_in'] = (df[f'NIWR_12_{yr-1:02d}'] / 25.4)\n",
    "    df[f'NIWR_01_{yr:02d}_in'] = (df[f'NIWR_01_{yr:02d}'] / 25.4)\n",
    "    df[f'NIWR_02_{yr:02d}_in'] = (df[f'NIWR_02_{yr:02d}'] / 25.4)\n",
    "    df[f'NIWR_03_{yr:02d}_in'] = (df[f'NIWR_03_{yr:02d}'] / 25.4)\n",
    "    df[f'NIWR_04_{yr:02d}_in'] = (df[f'NIWR_04_{yr:02d}'] / 25.4)\n",
    "    df[f'NIWR_05_{yr:02d}_in'] = (df[f'NIWR_05_{yr:02d}'] / 25.4)\n",
    "    df[f'NIWR_06_{yr:02d}_in'] = (df[f'NIWR_06_{yr:02d}'] / 25.4)\n",
    "    df[f'NIWR_07_{yr:02d}_in'] = (df[f'NIWR_07_{yr:02d}'] / 25.4)\n",
    "    df[f'NIWR_08_{yr:02d}_in'] = (df[f'NIWR_08_{yr:02d}'] / 25.4)\n",
    "    df[f'NIWR_09_{yr:02d}_in'] = (df[f'NIWR_09_{yr:02d}'] / 25.4)\n",
    "    df[f'NIWR_10_{yr:02d}_in'] = (df[f'NIWR_10_{yr:02d}'] / 25.4)\n",
    "    \n",
    "    # calculate volumes of each monthly value for all variables\n",
    "    if yr == 0:\n",
    "        df[f'ET_VOLUME_11_99_acft'] = (df[f'ETa_11_99_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "        df[f'ET_VOLUME_12_99_acft'] = (df[f'ETa_12_99_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']        \n",
    "    else:\n",
    "        df[f'ET_VOLUME_11_{yr-1:02d}_acft'] = (df[f'ETa_11_{yr-1:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "        df[f'ET_VOLUME_12_{yr-1:02d}_acft'] = (df[f'ETa_12_{yr-1:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ET_VOLUME_01_{yr:02d}_acft'] = (df[f'ETa_01_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ET_VOLUME_02_{yr:02d}_acft'] = (df[f'ETa_02_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ET_VOLUME_03_{yr:02d}_acft'] = (df[f'ETa_03_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ET_VOLUME_04_{yr:02d}_acft'] = (df[f'ETa_04_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ET_VOLUME_05_{yr:02d}_acft'] = (df[f'ETa_05_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ET_VOLUME_06_{yr:02d}_acft'] = (df[f'ETa_06_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ET_VOLUME_07_{yr:02d}_acft'] = (df[f'ETa_07_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ET_VOLUME_08_{yr:02d}_acft'] = (df[f'ETa_08_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ET_VOLUME_09_{yr:02d}_acft'] = (df[f'ETa_09_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ET_VOLUME_10_{yr:02d}_acft'] = (df[f'ETa_10_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    \n",
    "    # calculate volumes of each monthly value for all variables\n",
    "    if yr == 0:\n",
    "        df[f'ETDa_VOLUME_11_99_acft'] = (df[f'ETDa_11_99_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "        df[f'ETDa_VOLUME_12_99_acft'] = (df[f'ETDa_12_99_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    else:\n",
    "        df[f'ETDa_VOLUME_11_{yr-1:02d}_acft'] = (df[f'ETDa_11_{yr-1:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "        df[f'ETDa_VOLUME_12_{yr-1:02d}_acft'] = (df[f'ETDa_12_{yr-1:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETDa_VOLUME_01_{yr:02d}_acft'] = (df[f'ETDa_01_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETDa_VOLUME_02_{yr:02d}_acft'] = (df[f'ETDa_02_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETDa_VOLUME_03_{yr:02d}_acft'] = (df[f'ETDa_03_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETDa_VOLUME_04_{yr:02d}_acft'] = (df[f'ETDa_04_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETDa_VOLUME_05_{yr:02d}_acft'] = (df[f'ETDa_05_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETDa_VOLUME_06_{yr:02d}_acft'] = (df[f'ETDa_06_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETDa_VOLUME_07_{yr:02d}_acft'] = (df[f'ETDa_07_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETDa_VOLUME_08_{yr:02d}_acft'] = (df[f'ETDa_08_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETDa_VOLUME_09_{yr:02d}_acft'] = (df[f'ETDa_09_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETDa_VOLUME_10_{yr:02d}_acft'] = (df[f'ETDa_10_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "\n",
    "    if yr == 0:\n",
    "        df[f'ETO_VOLUME_11_99_acft'] = (df[f'ET_Reference_11_99_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "        df[f'ETO_VOLUME_12_99_acft'] = (df[f'ET_Reference_12_99_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    else:\n",
    "        df[f'ETO_VOLUME_11_{yr-1:02d}_acft'] = (df[f'ET_Reference_11_{yr-1:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "        df[f'ETO_VOLUME_12_{yr-1:02d}_acft'] = (df[f'ET_Reference_12_{yr-1:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETO_VOLUME_01_{yr:02d}_acft'] = (df[f'ET_Reference_01_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETO_VOLUME_02_{yr:02d}_acft'] = (df[f'ET_Reference_02_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETO_VOLUME_03_{yr:02d}_acft'] = (df[f'ET_Reference_03_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETO_VOLUME_04_{yr:02d}_acft'] = (df[f'ET_Reference_04_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETO_VOLUME_05_{yr:02d}_acft'] = (df[f'ET_Reference_05_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETO_VOLUME_06_{yr:02d}_acft'] = (df[f'ET_Reference_06_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETO_VOLUME_07_{yr:02d}_acft'] = (df[f'ET_Reference_07_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETO_VOLUME_08_{yr:02d}_acft'] = (df[f'ET_Reference_08_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETO_VOLUME_09_{yr:02d}_acft'] = (df[f'ET_Reference_09_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'ETO_VOLUME_10_{yr:02d}_acft'] = (df[f'ET_Reference_10_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    " \n",
    "    if yr == 0:\n",
    "        df[f'PPT_VOLUME_11_99_acft'] = (df[f'PPT_11_99_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "        df[f'PPT_VOLUME_12_99_acft'] = (df[f'PPT_12_99_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']    \n",
    "    else:\n",
    "        df[f'PPT_VOLUME_11_{yr-1:02d}_acft'] = (df[f'PPT_11_{yr-1:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "        df[f'PPT_VOLUME_12_{yr-1:02d}_acft'] = (df[f'PPT_12_{yr-1:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'PPT_VOLUME_01_{yr:02d}_acft'] = (df[f'PPT_01_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'PPT_VOLUME_02_{yr:02d}_acft'] = (df[f'PPT_02_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'PPT_VOLUME_03_{yr:02d}_acft'] = (df[f'PPT_03_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'PPT_VOLUME_04_{yr:02d}_acft'] = (df[f'PPT_04_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'PPT_VOLUME_05_{yr:02d}_acft'] = (df[f'PPT_05_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'PPT_VOLUME_06_{yr:02d}_acft'] = (df[f'PPT_06_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'PPT_VOLUME_07_{yr:02d}_acft'] = (df[f'PPT_07_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'PPT_VOLUME_08_{yr:02d}_acft'] = (df[f'PPT_08_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'PPT_VOLUME_09_{yr:02d}_acft'] = (df[f'PPT_09_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'PPT_VOLUME_10_{yr:02d}_acft'] = (df[f'PPT_10_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "\n",
    "    if yr == 0:\n",
    "        df[f'EFF_VOLUME_11_99_acft'] = (df[f'{eff_ppt_var}_11_99_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "        df[f'EFF_VOLUME_12_99_acft'] = (df[f'{eff_ppt_var}_12_99_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']    \n",
    "    else:\n",
    "        df[f'EFF_VOLUME_11_{yr-1:02d}_acft'] = (df[f'{eff_ppt_var}_11_{yr-1:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "        df[f'EFF_VOLUME_12_{yr-1:02d}_acft'] = (df[f'{eff_ppt_var}_12_{yr-1:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'EFF_VOLUME_01_{yr:02d}_acft'] = (df[f'{eff_ppt_var}_01_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'EFF_VOLUME_02_{yr:02d}_acft'] = (df[f'{eff_ppt_var}_02_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'EFF_VOLUME_03_{yr:02d}_acft'] = (df[f'{eff_ppt_var}_03_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'EFF_VOLUME_04_{yr:02d}_acft'] = (df[f'{eff_ppt_var}_04_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'EFF_VOLUME_05_{yr:02d}_acft'] = (df[f'{eff_ppt_var}_05_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'EFF_VOLUME_06_{yr:02d}_acft'] = (df[f'{eff_ppt_var}_06_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'EFF_VOLUME_07_{yr:02d}_acft'] = (df[f'{eff_ppt_var}_07_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'EFF_VOLUME_08_{yr:02d}_acft'] = (df[f'{eff_ppt_var}_08_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'EFF_VOLUME_09_{yr:02d}_acft'] = (df[f'{eff_ppt_var}_09_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "    df[f'EFF_VOLUME_10_{yr:02d}_acft'] = (df[f'{eff_ppt_var}_10_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}']\n",
    "\n",
    "    # cap the effective ppt from ET Demands to the max (total precip) from the field averaged gridMET ppt\n",
    "    # if yr == 0:\n",
    "    #     df.loc[df[f'EFF_VOLUME_11_99_acft'] > df[f'PPT_VOLUME_11_99_acft'], f'EFF_VOLUME_11_99_acft'] = df[f'PPT_VOLUME_11_99_acft']\n",
    "    #     df.loc[df[f'EFF_VOLUME_12_99_acft'] > df[f'PPT_VOLUME_11_99_acft'], f'EFF_VOLUME_11_99_acft'] = df[f'PPT_VOLUME_11_99_acft']    \n",
    "    # else:\n",
    "    #     df.loc[df[f'EFF_VOLUME_11_{yr-1:02d}_acft'] > df[f'PPT_VOLUME_11_{yr-1:02d}_acft'], f'EFF_VOLUME_11_{yr-1:02d}_acft'] = df[f'PPT_VOLUME_11_{yr-1:02d}_acft']\n",
    "    #     df.loc[df[f'EFF_VOLUME_12_{yr-1:02d}_acft'] > df[f'PPT_VOLUME_11_{yr-1:02d}_acft'], f'EFF_VOLUME_11_{yr-1:02d}_acft'] = df[f'PPT_VOLUME_11_{yr-1:02d}_acft']\n",
    "    # df.loc[df[f'EFF_VOLUME_01_{yr:02d}_acft'] > df[f'PPT_VOLUME_01_{yr:02d}_acft'], f'EFF_VOLUME_01_{yr:02d}_acft'] = df[f'PPT_VOLUME_01_{yr:02d}_acft']\n",
    "    # df.loc[df[f'EFF_VOLUME_02_{yr:02d}_acft'] > df[f'PPT_VOLUME_02_{yr:02d}_acft'], f'EFF_VOLUME_02_{yr:02d}_acft'] = df[f'PPT_VOLUME_02_{yr:02d}_acft']\n",
    "    # df.loc[df[f'EFF_VOLUME_03_{yr:02d}_acft'] > df[f'PPT_VOLUME_03_{yr:02d}_acft'], f'EFF_VOLUME_03_{yr:02d}_acft'] = df[f'PPT_VOLUME_03_{yr:02d}_acft']\n",
    "    # df.loc[df[f'EFF_VOLUME_04_{yr:02d}_acft'] > df[f'PPT_VOLUME_04_{yr:02d}_acft'], f'EFF_VOLUME_04_{yr:02d}_acft'] = df[f'PPT_VOLUME_04_{yr:02d}_acft']\n",
    "    # df.loc[df[f'EFF_VOLUME_05_{yr:02d}_acft'] > df[f'PPT_VOLUME_05_{yr:02d}_acft'], f'EFF_VOLUME_05_{yr:02d}_acft'] = df[f'PPT_VOLUME_05_{yr:02d}_acft']\n",
    "    # df.loc[df[f'EFF_VOLUME_06_{yr:02d}_acft'] > df[f'PPT_VOLUME_06_{yr:02d}_acft'], f'EFF_VOLUME_06_{yr:02d}_acft'] = df[f'PPT_VOLUME_06_{yr:02d}_acft']\n",
    "    # df.loc[df[f'EFF_VOLUME_07_{yr:02d}_acft'] > df[f'PPT_VOLUME_07_{yr:02d}_acft'], f'EFF_VOLUME_07_{yr:02d}_acft'] = df[f'PPT_VOLUME_07_{yr:02d}_acft']\n",
    "    # df.loc[df[f'EFF_VOLUME_08_{yr:02d}_acft'] > df[f'PPT_VOLUME_08_{yr:02d}_acft'], f'EFF_VOLUME_08_{yr:02d}_acft'] = df[f'PPT_VOLUME_08_{yr:02d}_acft']\n",
    "    # df.loc[df[f'EFF_VOLUME_09_{yr:02d}_acft'] > df[f'PPT_VOLUME_09_{yr:02d}_acft'], f'EFF_VOLUME_09_{yr:02d}_acft'] = df[f'PPT_VOLUME_09_{yr:02d}_acft']\n",
    "    # df.loc[df[f'EFF_VOLUME_10_{yr:02d}_acft'] > df[f'PPT_VOLUME_10_{yr:02d}_acft'], f'EFF_VOLUME_10_{yr:02d}_acft'] = df[f'PPT_VOLUME_10_{yr:02d}_acft']\n",
    "    \n",
    "    # calculate the consumptive use by subtracting effective ppt from actual et\n",
    "    if yr == 0:\n",
    "        df[f'IRR_CU_VOLUME_11_99_acft'] = df[f'ET_VOLUME_11_99_acft'] - df[f'EFF_VOLUME_11_99_acft']\n",
    "        df[f'IRR_CU_VOLUME_12_99_acft'] = df[f'ET_VOLUME_12_99_acft'] - df[f'EFF_VOLUME_12_99_acft']        \n",
    "    else:\n",
    "        df[f'IRR_CU_VOLUME_11_{yr-1:02d}_acft'] = df[f'ET_VOLUME_11_{yr-1:02d}_acft'] - df[f'EFF_VOLUME_11_{yr-1:02d}_acft']\n",
    "        df[f'IRR_CU_VOLUME_12_{yr-1:02d}_acft'] = df[f'ET_VOLUME_12_{yr-1:02d}_acft'] - df[f'EFF_VOLUME_12_{yr-1:02d}_acft']\n",
    "    df[f'IRR_CU_VOLUME_01_{yr:02d}_acft'] = df[f'ET_VOLUME_01_{yr:02d}_acft'] - df[f'EFF_VOLUME_01_{yr:02d}_acft']\n",
    "    df[f'IRR_CU_VOLUME_02_{yr:02d}_acft'] = df[f'ET_VOLUME_02_{yr:02d}_acft'] - df[f'EFF_VOLUME_02_{yr:02d}_acft']\n",
    "    df[f'IRR_CU_VOLUME_03_{yr:02d}_acft'] = df[f'ET_VOLUME_03_{yr:02d}_acft'] - df[f'EFF_VOLUME_03_{yr:02d}_acft']\n",
    "    df[f'IRR_CU_VOLUME_04_{yr:02d}_acft'] = df[f'ET_VOLUME_04_{yr:02d}_acft'] - df[f'EFF_VOLUME_04_{yr:02d}_acft']\n",
    "    df[f'IRR_CU_VOLUME_05_{yr:02d}_acft'] = df[f'ET_VOLUME_05_{yr:02d}_acft'] - df[f'EFF_VOLUME_05_{yr:02d}_acft']\n",
    "    df[f'IRR_CU_VOLUME_06_{yr:02d}_acft'] = df[f'ET_VOLUME_06_{yr:02d}_acft'] - df[f'EFF_VOLUME_06_{yr:02d}_acft']\n",
    "    df[f'IRR_CU_VOLUME_07_{yr:02d}_acft'] = df[f'ET_VOLUME_07_{yr:02d}_acft'] - df[f'EFF_VOLUME_07_{yr:02d}_acft']\n",
    "    df[f'IRR_CU_VOLUME_08_{yr:02d}_acft'] = df[f'ET_VOLUME_08_{yr:02d}_acft'] - df[f'EFF_VOLUME_08_{yr:02d}_acft']\n",
    "    df[f'IRR_CU_VOLUME_09_{yr:02d}_acft'] = df[f'ET_VOLUME_09_{yr:02d}_acft'] - df[f'EFF_VOLUME_09_{yr:02d}_acft']\n",
    "    df[f'IRR_CU_VOLUME_10_{yr:02d}_acft'] = df[f'ET_VOLUME_10_{yr:02d}_acft'] - df[f'EFF_VOLUME_10_{yr:02d}_acft']\n",
    "\n",
    "    if yr == 0:\n",
    "        df[f'NIWR_VOLUME_11_99_acft'] = ((df[f'NIWR_11_99_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}'])\n",
    "        df[f'NIWR_VOLUME_12_99_acft'] = ((df[f'NIWR_12_99_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}'])   \n",
    "    else:\n",
    "        df[f'NIWR_VOLUME_11_{yr-1:02d}_acft'] = ((df[f'NIWR_11_{yr-1:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}'])\n",
    "        df[f'NIWR_VOLUME_12_{yr-1:02d}_acft'] = ((df[f'NIWR_12_{yr-1:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}'])\n",
    "    df[f'NIWR_VOLUME_01_{yr:02d}_acft'] = ((df[f'NIWR_01_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}'])\n",
    "    df[f'NIWR_VOLUME_02_{yr:02d}_acft'] = ((df[f'NIWR_02_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}'])\n",
    "    df[f'NIWR_VOLUME_03_{yr:02d}_acft'] = ((df[f'NIWR_03_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}'])\n",
    "    df[f'NIWR_VOLUME_04_{yr:02d}_acft'] = ((df[f'NIWR_04_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}'])\n",
    "    df[f'NIWR_VOLUME_05_{yr:02d}_acft'] = ((df[f'NIWR_05_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}'])\n",
    "    df[f'NIWR_VOLUME_06_{yr:02d}_acft'] = ((df[f'NIWR_06_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}'])\n",
    "    df[f'NIWR_VOLUME_07_{yr:02d}_acft'] = ((df[f'NIWR_07_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}'])\n",
    "    df[f'NIWR_VOLUME_08_{yr:02d}_acft'] = ((df[f'NIWR_08_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}'])\n",
    "    df[f'NIWR_VOLUME_09_{yr:02d}_acft'] = ((df[f'NIWR_09_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}'])\n",
    "    df[f'NIWR_VOLUME_10_{yr:02d}_acft'] = ((df[f'NIWR_10_{yr:02d}_in'] / 12) * df[f'ACRES_FTR_GEOM_{yr:02d}'])   \n",
    "    \n",
    "    \n",
    "# regular expression to find columns containing the list of substrings below \n",
    "reg1 = '|'.join([f'GEOM_{yr_abr_list[0]:02d}','HUC','OWRD','Region','ITYPE','IRR_EFF','srctype','GRIDMET','ACRES',f'IRRIGATED_{yr_abr_list[0]:02d}',f'WETLAND_{yr_abr_list[0]:02d}',f'{yr_abr_list[0]:02d}_MODE',f'ETD_{yr_abr_list[0]:02d}',\n",
    "                 f'ET_Fraction_11_{yr_abr_list[0]-1:02d}',f'ET_Fraction_12_{yr_abr_list[0]-1:02d}',f'ET_Fraction_01_{yr_abr_list[0]:02d}',f'ET_Fraction_02_{yr_abr_list[0]:02d}',\n",
    "                 f'ET_Fraction_03_{yr_abr_list[0]:02d}',f'ET_Fraction_04_{yr_abr_list[0]:02d}',f'ET_Fraction_05_{yr_abr_list[0]:02d}',f'ET_Fraction_06_{yr_abr_list[0]:02d}',\n",
    "                 f'ET_Fraction_07_{yr_abr_list[0]:02d}',f'ET_Fraction_08_{yr_abr_list[0]:02d}',f'ET_Fraction_09_{yr_abr_list[0]:02d}',f'ET_Fraction_10_{yr_abr_list[0]:02d}',\n",
    "                 f'11_{yr_abr_list[0]-1:02d}_in',f'12_{yr_abr_list[0]-1:02d}_in',f'01_{yr_abr_list[0]:02d}_in',f'02_{yr_abr_list[0]:02d}_in',f'03_{yr_abr_list[0]:02d}_in',\n",
    "                 f'04_{yr_abr_list[0]:02d}_in',f'05_{yr_abr_list[0]:02d}_in',f'06_{yr_abr_list[0]:02d}_in',f'07_{yr_abr_list[0]:02d}_in',f'08_{yr_abr_list[0]:02d}_in',\n",
    "                 f'09_{yr_abr_list[0]:02d}_in',f'10_{yr_abr_list[0]:02d}_in',f'11_{yr_abr_list[0]-1:02d}_acft',f'12_{yr_abr_list[0]-1:02d}_acft',f'01_{yr_abr_list[0]:02d}_acft',\n",
    "                 f'02_{yr_abr_list[0]:02d}_acft',f'03_{yr_abr_list[0]:02d}_acft',f'04_{yr_abr_list[0]:02d}_acft',f'05_{yr_abr_list[0]:02d}_acft',\n",
    "                 f'06_{yr_abr_list[0]:02d}_acft',f'07_{yr_abr_list[0]:02d}_acft',f'08_{yr_abr_list[0]:02d}_acft',f'09_{yr_abr_list[0]:02d}_acft',f'10_{yr_abr_list[0]:02d}_acft',f'{yr_list[0]}'])\n",
    "reg2 = '|'.join([f'GEOM_{yr_abr_list[1]:02d}','HUC','OWRD','Region','ITYPE','IRR_EFF','srctype','GRIDMET','ACRES',f'IRRIGATED_{yr_abr_list[1]:02d}',f'WETLAND_{yr_abr_list[1]:02d}',f'{yr_abr_list[1]:02d}_MODE',f'ETD_{yr_abr_list[1]:02d}',\n",
    "                 f'ET_Fraction_11_{yr_abr_list[1]-1:02d}',f'ET_Fraction_12_{yr_abr_list[1]-1:02d}',f'ET_Fraction_01_{yr_abr_list[1]:02d}',f'ET_Fraction_02_{yr_abr_list[1]:02d}',\n",
    "                 f'ET_Fraction_03_{yr_abr_list[1]:02d}',f'ET_Fraction_04_{yr_abr_list[1]:02d}',f'ET_Fraction_05_{yr_abr_list[1]:02d}',f'ET_Fraction_06_{yr_abr_list[1]:02d}',\n",
    "                 f'ET_Fraction_07_{yr_abr_list[1]:02d}',f'ET_Fraction_08_{yr_abr_list[1]:02d}',f'ET_Fraction_09_{yr_abr_list[1]:02d}',f'ET_Fraction_10_{yr_abr_list[1]:02d}',\n",
    "                 f'11_{yr_abr_list[1]-1:02d}_in',f'12_{yr_abr_list[1]-1:02d}_in',f'01_{yr_abr_list[1]:02d}_in',f'02_{yr_abr_list[1]:02d}_in',f'03_{yr_abr_list[1]:02d}_in',f'04_{yr_abr_list[1]:02d}_in',f'05_{yr_abr_list[1]:02d}_in',\n",
    "                 f'06_{yr_abr_list[1]:02d}_in',f'07_{yr_abr_list[1]:02d}_in',f'08_{yr_abr_list[1]:02d}_in',f'09_{yr_abr_list[1]:02d}_in',f'10_{yr_abr_list[1]:02d}_in',f'11_{yr_abr_list[1]-1:02d}_acft',f'12_{yr_abr_list[1]-1:02d}_acft',\n",
    "                 f'01_{yr_abr_list[1]:02d}_acft',f'02_{yr_abr_list[1]:02d}_acft',f'03_{yr_abr_list[1]:02d}_acft',f'04_{yr_abr_list[1]:02d}_acft',f'05_{yr_abr_list[1]:02d}_acft',\n",
    "                 f'06_{yr_abr_list[1]:02d}_acft',f'07_{yr_abr_list[1]:02d}_acft',f'08_{yr_abr_list[1]:02d}_acft',f'09_{yr_abr_list[1]:02d}_acft',f'10_{yr_abr_list[1]:02d}_acft',f'{yr_list[1]}'])\n",
    "if 0 in yr_abr_list:\n",
    "    reg3 = '|'.join([f'GEOM_{yr_abr_list[2]:02d}','HUC','OWRD','Region','ITYPE','IRR_EFF','srctype','GRIDMET','ACRES',f'IRRIGATED_{yr_abr_list[2]:02d}',f'WETLAND_{yr_abr_list[2]:02d}',f'{yr_abr_list[2]:02d}_MODE',f'ETD_{yr_abr_list[2]:02d}',\n",
    "                     'ET_Fraction_11_99','ET_Fraction_12_99',f'ET_Fraction_01_{yr_abr_list[2]:02d}',f'ET_Fraction_02_{yr_abr_list[2]:02d}',\n",
    "                     f'ET_Fraction_03_{yr_abr_list[2]:02d}',f'ET_Fraction_04_{yr_abr_list[2]:02d}',f'ET_Fraction_05_{yr_abr_list[2]:02d}',f'ET_Fraction_06_{yr_abr_list[2]:02d}',\n",
    "                     f'ET_Fraction_07_{yr_abr_list[2]:02d}',f'ET_Fraction_08_{yr_abr_list[2]:02d}',f'ET_Fraction_09_{yr_abr_list[2]:02d}',f'ET_Fraction_10_{yr_abr_list[2]:02d}',\n",
    "                     '11_99_in','12_99_in',f'01_{yr_abr_list[2]:02d}_in',f'02_{yr_abr_list[2]:02d}_in',f'03_{yr_abr_list[2]:02d}_in',f'04_{yr_abr_list[2]:02d}_in',f'05_{yr_abr_list[2]:02d}_in',\n",
    "                     f'06_{yr_abr_list[2]:02d}_in',f'07_{yr_abr_list[2]:02d}_in',f'08_{yr_abr_list[2]:02d}_in',f'09_{yr_abr_list[2]:02d}_in',f'10_{yr_abr_list[2]:02d}_in','11_99_acft','12_99_acft',\n",
    "                     f'01_{yr_abr_list[2]:02d}_acft',f'02_{yr_abr_list[2]:02d}_acft',f'03_{yr_abr_list[2]:02d}_acft',f'04_{yr_abr_list[2]:02d}_acft',f'05_{yr_abr_list[2]:02d}_acft',\n",
    "                     f'06_{yr_abr_list[2]:02d}_acft',f'07_{yr_abr_list[2]:02d}_acft',f'08_{yr_abr_list[2]:02d}_acft',f'09_{yr_abr_list[2]:02d}_acft',f'10_{yr_abr_list[2]:02d}_acft',f'{yr_list[2]}'])\n",
    "else:\n",
    "    reg3 = '|'.join([f'GEOM_{yr_abr_list[2]:02d}','HUC','OWRD','Region','ITYPE','IRR_EFF','srctype','GRIDMET','ACRES',f'IRRIGATED_{yr_abr_list[2]:02d}',f'WETLAND_{yr_abr_list[2]:02d}',f'{yr_abr_list[2]:02d}_MODE',f'ETD_{yr_abr_list[2]:02d}',\n",
    "                     f'ET_Fraction_11_{yr_abr_list[2]-1:02d}',f'ET_Fraction_12_{yr_abr_list[2]-1:02d}',f'ET_Fraction_01_{yr_abr_list[2]:02d}',f'ET_Fraction_02_{yr_abr_list[2]:02d}',\n",
    "                     f'ET_Fraction_03_{yr_abr_list[2]:02d}',f'ET_Fraction_04_{yr_abr_list[2]:02d}',f'ET_Fraction_05_{yr_abr_list[2]:02d}',f'ET_Fraction_06_{yr_abr_list[2]:02d}',\n",
    "                     f'ET_Fraction_07_{yr_abr_list[2]:02d}',f'ET_Fraction_08_{yr_abr_list[2]:02d}',f'ET_Fraction_09_{yr_abr_list[2]:02d}',f'ET_Fraction_10_{yr_abr_list[2]:02d}',\n",
    "                     f'11_{yr_abr_list[2]-1:02d}_in',f'12_{yr_abr_list[2]-1:02d}_in',f'01_{yr_abr_list[2]:02d}_in',f'02_{yr_abr_list[2]:02d}_in',f'03_{yr_abr_list[2]:02d}_in',f'04_{yr_abr_list[2]:02d}_in',f'05_{yr_abr_list[2]:02d}_in',\n",
    "                     f'06_{yr_abr_list[2]:02d}_in',f'07_{yr_abr_list[2]:02d}_in',f'08_{yr_abr_list[2]:02d}_in',f'09_{yr_abr_list[2]:02d}_in',f'10_{yr_abr_list[2]:02d}_in',f'11_{yr_abr_list[2]-1:02d}_acft',f'12_{yr_abr_list[2]-1:02d}_acft',\n",
    "                     f'01_{yr_abr_list[2]:02d}_acft',f'02_{yr_abr_list[2]:02d}_acft',f'03_{yr_abr_list[2]:02d}_acft',f'04_{yr_abr_list[2]:02d}_acft',f'05_{yr_abr_list[2]:02d}_acft',\n",
    "                     f'06_{yr_abr_list[2]:02d}_acft',f'07_{yr_abr_list[2]:02d}_acft',f'08_{yr_abr_list[2]:02d}_acft',f'09_{yr_abr_list[2]:02d}_acft',f'10_{yr_abr_list[2]:02d}_acft',f'{yr_list[2]}'])\n",
    "reg4 = '|'.join([f'GEOM_{yr_abr_list[3]:02d}','HUC','OWRD','Region','ITYPE','IRR_EFF','srctype','GRIDMET','ACRES',f'IRRIGATED_{yr_abr_list[3]:02d}',f'WETLAND_{yr_abr_list[3]:02d}',f'{yr_abr_list[3]:02d}_MODE',f'ETD_{yr_abr_list[3]:02d}',\n",
    "                 f'ET_Fraction_11_{yr_abr_list[3]-1:02d}',f'ET_Fraction_12_{yr_abr_list[3]-1:02d}',f'ET_Fraction_01_{yr_abr_list[3]:02d}',f'ET_Fraction_02_{yr_abr_list[3]:02d}',\n",
    "                 f'ET_Fraction_03_{yr_abr_list[3]:02d}',f'ET_Fraction_04_{yr_abr_list[3]:02d}',f'ET_Fraction_05_{yr_abr_list[3]:02d}',f'ET_Fraction_06_{yr_abr_list[3]:02d}',\n",
    "                 f'ET_Fraction_07_{yr_abr_list[3]:02d}',f'ET_Fraction_08_{yr_abr_list[3]:02d}',f'ET_Fraction_09_{yr_abr_list[3]:02d}',f'ET_Fraction_10_{yr_abr_list[3]:02d}',\n",
    "                 f'11_{yr_abr_list[3]-1:02d}_in',f'12_{yr_abr_list[3]-1:02d}_in',f'01_{yr_abr_list[3]:02d}_in',f'02_{yr_abr_list[3]:02d}_in',f'03_{yr_abr_list[3]:02d}_in',f'04_{yr_abr_list[3]:02d}_in',f'05_{yr_abr_list[3]:02d}_in',\n",
    "                 f'06_{yr_abr_list[3]:02d}_in',f'07_{yr_abr_list[3]:02d}_in',f'08_{yr_abr_list[3]:02d}_in',f'09_{yr_abr_list[3]:02d}_in',f'10_{yr_abr_list[3]:02d}_in',f'11_{yr_abr_list[3]-1:02d}_acft',f'12_{yr_abr_list[3]-1:02d}_acft',\n",
    "                 f'01_{yr_abr_list[3]:02d}_acft',f'02_{yr_abr_list[3]:02d}_acft',f'03_{yr_abr_list[3]:02d}_acft',f'04_{yr_abr_list[3]:02d}_acft',f'05_{yr_abr_list[3]:02d}_acft',\n",
    "                 f'06_{yr_abr_list[3]:02d}_acft',f'07_{yr_abr_list[3]:02d}_acft',f'08_{yr_abr_list[3]:02d}_acft',f'09_{yr_abr_list[3]:02d}_acft',f'10_{yr_abr_list[3]:02d}_acft',f'{yr_list[3]}'])\n",
    "reg5 = '|'.join([f'GEOM_{yr_abr_list[4]:02d}','HUC','OWRD','Region','ITYPE','IRR_EFF','srctype','GRIDMET','ACRES',f'IRRIGATED_{yr_abr_list[4]:02d}',f'WETLAND_{yr_abr_list[4]:02d}',f'{yr_abr_list[4]:02d}_MODE',f'ETD_{yr_abr_list[4]:02d}',\n",
    "                 f'ET_Fraction_11_{yr_abr_list[4]-1:02d}',f'ET_Fraction_12_{yr_abr_list[4]-1:02d}',f'ET_Fraction_01_{yr_abr_list[4]:02d}',f'ET_Fraction_02_{yr_abr_list[4]:02d}',\n",
    "                 f'ET_Fraction_03_{yr_abr_list[4]:02d}',f'ET_Fraction_04_{yr_abr_list[4]:02d}',f'ET_Fraction_05_{yr_abr_list[4]:02d}',f'ET_Fraction_06_{yr_abr_list[4]:02d}',\n",
    "                 f'ET_Fraction_07_{yr_abr_list[4]:02d}',f'ET_Fraction_08_{yr_abr_list[4]:02d}',f'ET_Fraction_09_{yr_abr_list[4]:02d}',f'ET_Fraction_10_{yr_abr_list[4]:02d}',\n",
    "                 f'11_{yr_abr_list[4]-1:02d}_in',f'12_{yr_abr_list[4]-1:02d}_in',f'01_{yr_abr_list[4]:02d}_in',f'02_{yr_abr_list[4]:02d}_in',f'03_{yr_abr_list[4]:02d}_in',f'04_{yr_abr_list[4]:02d}_in',f'05_{yr_abr_list[4]:02d}_in',\n",
    "                 f'06_{yr_abr_list[4]:02d}_in',f'07_{yr_abr_list[4]:02d}_in',f'08_{yr_abr_list[4]:02d}_in',f'09_{yr_abr_list[4]:02d}_in',f'10_{yr_abr_list[4]:02d}_in',f'11_{yr_abr_list[4]-1:02d}_acft',f'12_{yr_abr_list[4]-1:02d}_acft',\n",
    "                 f'01_{yr_abr_list[4]:02d}_acft',f'02_{yr_abr_list[4]:02d}_acft',f'03_{yr_abr_list[4]:02d}_acft',f'04_{yr_abr_list[4]:02d}_acft',f'05_{yr_abr_list[4]:02d}_acft',\n",
    "                 f'06_{yr_abr_list[4]:02d}_acft',f'07_{yr_abr_list[4]:02d}_acft',f'08_{yr_abr_list[4]:02d}_acft',f'09_{yr_abr_list[4]:02d}_acft',f'10_{yr_abr_list[4]:02d}_acft',f'{yr_list[4]}'])\n",
    "reg6 = '|'.join([f'GEOM_{yr_abr_list[5]:02d}','HUC','OWRD','Region','ITYPE','IRR_EFF','srctype','GRIDMET','ACRES',f'IRRIGATED_{yr_abr_list[5]:02d}',f'WETLAND_{yr_abr_list[5]:02d}',f'{yr_abr_list[5]:02d}_MODE',f'ETD_{yr_abr_list[5]:02d}',\n",
    "                 f'ET_Fraction_11_{yr_abr_list[5]-1:02d}',f'ET_Fraction_12_{yr_abr_list[5]-1:02d}',f'ET_Fraction_01_{yr_abr_list[5]:02d}',f'ET_Fraction_02_{yr_abr_list[5]:02d}',\n",
    "                 f'ET_Fraction_03_{yr_abr_list[5]:02d}',f'ET_Fraction_04_{yr_abr_list[5]:02d}',f'ET_Fraction_05_{yr_abr_list[5]:02d}',f'ET_Fraction_06_{yr_abr_list[5]:02d}',\n",
    "                 f'ET_Fraction_07_{yr_abr_list[5]:02d}',f'ET_Fraction_08_{yr_abr_list[5]:02d}',f'ET_Fraction_09_{yr_abr_list[5]:02d}',f'ET_Fraction_10_{yr_abr_list[5]:02d}',\n",
    "                 f'11_{yr_abr_list[5]-1:02d}_in',f'12_{yr_abr_list[5]-1:02d}_in',f'01_{yr_abr_list[5]:02d}_in',f'02_{yr_abr_list[5]:02d}_in',f'03_{yr_abr_list[5]:02d}_in',f'04_{yr_abr_list[5]:02d}_in',f'05_{yr_abr_list[5]:02d}_in',\n",
    "                 f'06_{yr_abr_list[5]:02d}_in',f'07_{yr_abr_list[5]:02d}_in',f'08_{yr_abr_list[5]:02d}_in',f'09_{yr_abr_list[5]:02d}_in',f'10_{yr_abr_list[5]:02d}_in',f'11_{yr_abr_list[5]-1:02d}_acft',f'12_{yr_abr_list[5]-1:02d}_acft',\n",
    "                 f'01_{yr_abr_list[5]:02d}_acft',f'02_{yr_abr_list[5]:02d}_acft',f'03_{yr_abr_list[5]:02d}_acft',f'04_{yr_abr_list[5]:02d}_acft',f'05_{yr_abr_list[5]:02d}_acft',\n",
    "                 f'06_{yr_abr_list[5]:02d}_acft',f'07_{yr_abr_list[5]:02d}_acft',f'08_{yr_abr_list[5]:02d}_acft',f'09_{yr_abr_list[5]:02d}_acft',f'10_{yr_abr_list[5]:02d}_acft',f'{yr_list[5]}'])\n",
    "reg7 = '|'.join([f'GEOM_{yr_abr_list[6]:02d}','HUC','OWRD','Region','ITYPE','IRR_EFF','srctype','GRIDMET','ACRES',f'IRRIGATED_{yr_abr_list[6]:02d}',f'WETLAND_{yr_abr_list[6]:02d}',f'{yr_abr_list[6]:02d}_MODE',f'ETD_{yr_abr_list[6]:02d}',\n",
    "                 f'ET_Fraction_11_{yr_abr_list[6]-1:02d}',f'ET_Fraction_12_{yr_abr_list[6]-1:02d}',f'ET_Fraction_01_{yr_abr_list[6]:02d}',f'ET_Fraction_02_{yr_abr_list[6]:02d}',\n",
    "                 f'ET_Fraction_03_{yr_abr_list[6]:02d}',f'ET_Fraction_04_{yr_abr_list[6]:02d}',f'ET_Fraction_05_{yr_abr_list[6]:02d}',f'ET_Fraction_06_{yr_abr_list[6]:02d}',\n",
    "                 f'ET_Fraction_07_{yr_abr_list[6]:02d}',f'ET_Fraction_08_{yr_abr_list[6]:02d}',f'ET_Fraction_09_{yr_abr_list[6]:02d}',f'ET_Fraction_10_{yr_abr_list[6]:02d}',\n",
    "                 f'11_{yr_abr_list[6]-1:02d}_in',f'12_{yr_abr_list[6]-1:02d}_in',f'01_{yr_abr_list[6]:02d}_in',f'02_{yr_abr_list[6]:02d}_in',f'03_{yr_abr_list[6]:02d}_in',f'04_{yr_abr_list[6]:02d}_in',f'05_{yr_abr_list[6]:02d}_in',\n",
    "                 f'06_{yr_abr_list[6]:02d}_in',f'07_{yr_abr_list[6]:02d}_in',f'08_{yr_abr_list[6]:02d}_in',f'09_{yr_abr_list[6]:02d}_in',f'10_{yr_abr_list[6]:02d}_in',f'11_{yr_abr_list[6]-1:02d}_acft',f'12_{yr_abr_list[6]-1:02d}_acft',\n",
    "                 f'01_{yr_abr_list[6]:02d}_acft',f'02_{yr_abr_list[6]:02d}_acft',f'03_{yr_abr_list[6]:02d}_acft',f'04_{yr_abr_list[6]:02d}_acft',f'05_{yr_abr_list[6]:02d}_acft',\n",
    "                 f'06_{yr_abr_list[6]:02d}_acft',f'07_{yr_abr_list[6]:02d}_acft',f'08_{yr_abr_list[6]:02d}_acft',f'09_{yr_abr_list[6]:02d}_acft',f'10_{yr_abr_list[6]:02d}_acft',f'{yr_list[6]}'])\n",
    "\n",
    "# use regex matches to extract columsn for output files\n",
    "df1o = df.loc[:,df.columns.str.contains(reg1)]\n",
    "df2o = df.loc[:,df.columns.str.contains(reg2)]\n",
    "df3o = df.loc[:,df.columns.str.contains(reg3)]\n",
    "df4o = df.loc[:,df.columns.str.contains(reg4)]\n",
    "df5o = df.loc[:,df.columns.str.contains(reg5)]\n",
    "df6o = df.loc[:,df.columns.str.contains(reg6)]\n",
    "\n",
    "# remove duplicate columns (static attributes)\n",
    "df1o = df1o.loc[:,~df1o.columns.duplicated()].copy()\n",
    "df2o = df2o.loc[:,~df2o.columns.duplicated()].copy()\n",
    "df3o = df3o.loc[:,~df3o.columns.duplicated()].copy()\n",
    "df4o = df4o.loc[:,~df4o.columns.duplicated()].copy()\n",
    "df5o = df5o.loc[:,~df5o.columns.duplicated()].copy()\n",
    "df6o = df6o.loc[:,~df6o.columns.duplicated()].copy()\n",
    "\n",
    "df1o = df1o.reset_index()\n",
    "df2o = df2o.reset_index()\n",
    "df3o = df3o.reset_index()\n",
    "df4o = df4o.reset_index()\n",
    "df5o = df5o.reset_index()\n",
    "df6o = df6o.reset_index()\n",
    "\n",
    "# export files to CSV's\n",
    "df1o.to_csv(os.path.join(out_path, f'or_openet_etdemands_monthly_water_year_shift_1mo_{yr_list[0]}_gap_filled.csv'), index=False)\n",
    "df2o.to_csv(os.path.join(out_path, f'or_openet_etdemands_monthly_water_year_shift_1mo_{yr_list[1]}_gap_filled.csv'), index=False)\n",
    "df3o.to_csv(os.path.join(out_path, f'or_openet_etdemands_monthly_water_year_shift_1mo_{yr_list[2]}_gap_filled.csv'), index=False)\n",
    "df4o.to_csv(os.path.join(out_path, f'or_openet_etdemands_monthly_water_year_shift_1mo_{yr_list[3]}_gap_filled.csv'), index=False)\n",
    "df5o.to_csv(os.path.join(out_path, f'or_openet_etdemands_monthly_water_year_shift_1mo_{yr_list[4]}_gap_filled.csv'), index=False)\n",
    "df6o.to_csv(os.path.join(out_path, f'or_openet_etdemands_monthly_water_year_shift_1mo_{yr_list[5]}_gap_filled.csv'), index=False)\n",
    "\n",
    "# additional year of processing done for certain windows\n",
    "if (yr_list[0] == 1985 and yr_list[-1] == 1991) or (yr_list[0] == 2016 and yr_list[-1] == 2022):\n",
    "    \n",
    "    df7o = df.loc[:,df.columns.str.contains(reg7)]\n",
    "    \n",
    "    df7o = df7o.loc[:,~df7o.columns.duplicated()].copy()\n",
    "    \n",
    "    df7o = df7o.reset_index()\n",
    "\n",
    "    df7o.to_csv(os.path.join(out_path, f'or_openet_etdemands_monthly_water_year_shift_1mo_{yr_list[6]}_gap_filled.csv'), index=False)\n",
    "\n",
    "print('exported all annual files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b26702-8dd6-4b7c-9ec5-b56a2ba711ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Soil moisture carry forward and applied water calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aa7f2b-5e4f-45a8-949a-3dd2f043051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "in_path = table_path.replace('ee_exports', 'post_processing\\\\4_gap_filled')\n",
    "\n",
    "out_path = table_path.replace('ee_exports', 'post_processing\\\\5_field_geodatabase')\n",
    "\n",
    "# list of years based on start/end year parameters\n",
    "year_list = list(range(start_year, end_year+1))\n",
    "\n",
    "# list of months to loop through\n",
    "mo_list = [11,12,1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "for year in year_list:\n",
    "\n",
    "    df = pd.read_csv(os.path.join(in_path, f'or_openet_etdemands_monthly_water_year_shift_1mo_{year}_gap_filled.csv'), index_col='OPENET_ID')\n",
    "    \n",
    "    if year == 1985:\n",
    "        # have to fill/remake a column each year to carry forward the cumulative WS\n",
    "        df_cf = df[['ACRES_FTR_GEOM_85', 'HUC8']].copy()\n",
    "\n",
    "        df_cf['WS_C_Carry_Forward'] = np.nan\n",
    "        \n",
    "    if year == 1985:\n",
    "        \n",
    "        for mo in mo_list:\n",
    "\n",
    "            if (mo == 11 or mo == 12):\n",
    "\n",
    "                # WS is equal to Net ET when Net ET is negative, overwrite positive WS values below\n",
    "                df[f'WS_{mo}_{str(year-1)[2:]}_acft'] = df[f'IRR_CU_VOLUME_{mo}_{str(year-1)[2:]}_acft']\n",
    "\n",
    "                # if Net ET is positive, overwrite WS to be 0\n",
    "                df.loc[df[f'IRR_CU_VOLUME_{mo}_{str(year-1)[2:]}_acft'] > 0, f'WS_{mo}_{str(year-1)[2:]}_acft'] = 0\n",
    "\n",
    "                if (year == 1985 and mo == 11):\n",
    "\n",
    "                    # cumulative WS at first time step is equal to WS\n",
    "                    df[f'WS_C_{mo}_{str(year-1)[2:]}_acft'] = df[f'WS_{mo}_{str(year-1)[2:]}_acft']\n",
    "\n",
    "                    # overwrite cumulative WS to be 0 when Net ET is positive\n",
    "                    df.loc[df['IRR_CU_VOLUME_11_84_acft'] > 0, 'WS_C_11_84_acft'] = 0\n",
    "\n",
    "                    # new columns to account for adjustments\n",
    "                    df['IRR_CU_VOLUMEadj_11_84_acft'] = df['IRR_CU_VOLUME_11_84_acft']\n",
    "                    df.loc[df['IRR_CU_VOLUME_11_84_acft'] < 0, 'IRR_CU_VOLUMEadj_11_84_acft'] = 0\n",
    "                    \n",
    "                    df['EFF_VOLUMEadj_11_84_acft'] = df['ET_VOLUME_11_84_acft'] - df['IRR_CU_VOLUMEadj_11_84_acft']\n",
    "                    \n",
    "                    # applied water at first time step is set to 0 unless we have a positive Net ET below\n",
    "                    df['AW_11_84_acft'] = 0\n",
    "\n",
    "                    # overwrite AW when Net ET is positive \n",
    "                    df.loc[df['IRR_CU_VOLUME_11_84_acft'] > 0, 'AW_11_84_acft'] = df['IRR_CU_VOLUME_11_84_acft'] / df['IRR_EFF']\n",
    "\n",
    "                    # overwrite AW when irrigation efficiency is 0\n",
    "                    df.loc[df['IRR_EFF'] == 0, 'AW_11_84_acft'] = np.nan\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "\n",
    "                    # cumulative WS set to 0\n",
    "                    df[f'WS_C_{mo}_{str(year-1)[2:]}_acft'] = 0\n",
    "\n",
    "                    # if the cumulative WS from previous month plus the current Net ET is negative, current cumulative WS is the sum of previous cumulative WS and current Net ET\n",
    "                    df.loc[(df[f'WS_C_{mo-1}_{str(year-1)[2:]}_acft'] + df[f'IRR_CU_VOLUME_{mo}_{str(year-1)[2:]}_acft']) < 0, f'WS_C_{mo}_{str(year-1)[2:]}_acft'] = df[f'WS_C_{mo-1}_{str(year-1)[2:]}_acft'] + df[f'IRR_CU_VOLUME_{mo}_{str(year-1)[2:]}_acft']\n",
    "\n",
    "                    # new columns to account for adjustments\n",
    "                    df[f'IRR_CU_VOLUMEadj_{mo}_{str(year-1)[2:]}_acft'] = df[f'IRR_CU_VOLUME_{mo}_{str(year-1)[2:]}_acft'] + df[f'WS_C_{mo-1}_{str(year-1)[2:]}_acft']\n",
    "                    df.loc[(df[f'IRR_CU_VOLUME_{mo}_{str(year-1)[2:]}_acft'] + df[f'WS_C_{mo-1}_{str(year-1)[2:]}_acft']) < 0, f'IRR_CU_VOLUMEadj_{mo}_{str(year-1)[2:]}_acft'] = 0\n",
    "                    \n",
    "                    df[f'EFF_VOLUMEadj_{mo}_{str(year-1)[2:]}_acft'] = df[f'ET_VOLUME_{mo}_{str(year-1)[2:]}_acft'] - df[f'IRR_CU_VOLUMEadj_{mo}_{str(year-1)[2:]}_acft']\n",
    "                    \n",
    "                    # set AW to be 0\n",
    "                    df[f'AW_{mo}_{str(year-1)[2:]}_acft'] = 0\n",
    "\n",
    "                    # if the current Net ET is positive, AW is calculated\n",
    "                    df.loc[df[f'IRR_CU_VOLUMEadj_{mo}_{str(year-1)[2:]}_acft'] > 0, f'AW_{mo}_{str(year-1)[2:]}_acft'] = df[f'IRR_CU_VOLUMEadj_{mo}_{str(year-1)[2:]}_acft'] / df['IRR_EFF']\n",
    "\n",
    "                    # overwrite negative applied water values with 0\n",
    "                    df.loc[df[f'AW_{mo}_{str(year-1)[2:]}_acft'] < 0, f'AW_{mo}_{str(year-1)[2:]}_acft'] = 0\n",
    "            \n",
    "                    # overwrite AW when irrigation efficiency is 0\n",
    "                    df.loc[df['IRR_EFF'] == 0, f'AW_{mo}_{str(year-1)[2:]}_acft'] = np.nan\n",
    "\n",
    "            else:\n",
    "                # WS is equal to Net ET when Net ET is negative, overwrite positive WS values below\n",
    "                df[f'WS_{mo:02d}_{str(year)[2:]}_acft'] = df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft']\n",
    "\n",
    "                # if Net ET is positive, overwrite WS to be 0\n",
    "                df.loc[df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft'] > 0, f'WS_{mo:02d}_{str(year)[2:]}_acft'] = 0\n",
    "\n",
    "                # cumulative WS at first time step is equal to WS\n",
    "                df[f'WS_C_{mo:02d}_{str(year)[2:]}_acft'] = 0\n",
    "\n",
    "                # if the cumulative WS from previous month plus the current Net ET is negative, current cumulative WS is the sum of previous cumulative WS and current Net ET\n",
    "                if mo == 1:\n",
    "                    # january needs to grab a value from previous year\n",
    "                    df.loc[(df[f'WS_C_12_{str(year-1)[2:]}_acft'] + df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft']) < 0, f'WS_C_{mo:02d}_{str(year)[2:]}_acft'] = df[f'WS_C_12_{str(year-1)[2:]}_acft'] + df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft']\n",
    "                    \n",
    "                    # new columns to account for adjustments\n",
    "                    df[f'IRR_CU_VOLUMEadj_{mo:02d}_{str(year)[2:]}_acft'] = df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft'] + df[f'WS_C_12_{str(year-1)[2:]}_acft']\n",
    "                    df.loc[(df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft'] + df[f'WS_C_12_{str(year-1)[2:]}_acft']) < 0, f'IRR_CU_VOLUMEadj_{mo:02d}_{str(year)[2:]}_acft'] = 0\n",
    "                else:   \n",
    "                    df.loc[(df[f'WS_C_{(mo-1):02d}_{str(year)[2:]}_acft'] + df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft']) < 0, f'WS_C_{mo:02d}_{str(year)[2:]}_acft'] = df[f'WS_C_{(mo-1):02d}_{str(year)[2:]}_acft'] + df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft']\n",
    "\n",
    "                    # new columns to account for adjustments\n",
    "                    df[f'IRR_CU_VOLUMEadj_{mo:02d}_{str(year)[2:]}_acft'] = df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft'] + df[f'WS_C_{(mo-1):02d}_{str(year)[2:]}_acft']\n",
    "                    df.loc[(df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft'] + df[f'WS_C_{(mo-1):02d}_{str(year)[2:]}_acft']) < 0, f'IRR_CU_VOLUMEadj_{mo:02d}_{str(year)[2:]}_acft'] = 0\n",
    "                    \n",
    "\n",
    "                df[f'EFF_VOLUMEadj_{mo:02d}_{str(year)[2:]}_acft'] = df[f'ET_VOLUME_{mo:02d}_{str(year)[2:]}_acft'] - df[f'IRR_CU_VOLUMEadj_{mo:02d}_{str(year)[2:]}_acft']                    \n",
    "                    \n",
    "                # set AW to be 0\n",
    "                df[f'AW_{mo:02d}_{str(year)[2:]}_acft'] = 0\n",
    "\n",
    "                # if the current Net ET is positive, AW is calculated\n",
    "                df.loc[df[f'IRR_CU_VOLUMEadj_{mo:02d}_{str(year)[2:]}_acft'] > 0, f'AW_{mo:02d}_{str(year)[2:]}_acft'] = df[f'IRR_CU_VOLUMEadj_{mo:02d}_{str(year)[2:]}_acft'] / df['IRR_EFF']\n",
    "\n",
    "                # overwrite negative applied water values with 0\n",
    "                df.loc[df[f'AW_{mo:02d}_{str(year)[2:]}_acft'] < 0, f'AW_{mo:02d}_{str(year)[2:]}_acft'] = 0\n",
    "                \n",
    "                # overwrite AW when irrigation efficiency is 0\n",
    "                df.loc[df['IRR_EFF'] == 0, f'AW_{mo:02d}_{str(year)[2:]}_acft'] = np.nan\n",
    "\n",
    "                if mo == 10:\n",
    "                    df_cf['WS_C_Carry_Forward'] = df['WS_C_10_85_acft']\n",
    "                \n",
    "    else:\n",
    "        \n",
    "        for mo in mo_list:\n",
    "\n",
    "            if mo == 11:\n",
    "\n",
    "                # WS is equal to Net ET when Net ET is negative, overwrite positive WS values below\n",
    "                df[f'WS_{mo}_{str(year-1)[2:]}_acft'] = df[f'IRR_CU_VOLUME_{mo}_{str(year-1)[2:]}_acft']\n",
    "\n",
    "                # if Net ET is positive, overwrite WS to be 0\n",
    "                df.loc[df[f'IRR_CU_VOLUME_{mo}_{str(year-1)[2:]}_acft'] > 0, f'WS_{mo}_{str(year-1)[2:]}_acft'] = 0\n",
    "\n",
    "                # cumulative WS for previous month set to the previous year's carry forward (Oct of the same year)\n",
    "                df[f'WS_C_{mo-1}_{str(year-1)[2:]}_acft'] = df_cf['WS_C_Carry_Forward']\n",
    "\n",
    "                # set initial cumulative WS and then check do the check below\n",
    "                df[f'WS_C_{mo}_{str(year-1)[2:]}_acft'] = 0\n",
    "                \n",
    "                # if the cumulative WS from previous month plus the current Net ET is negative, current cumulative WS is the sum of previous cumulative WS and current Net ET\n",
    "                df.loc[(df[f'WS_C_{mo-1}_{str(year-1)[2:]}_acft'] + df[f'IRR_CU_VOLUME_{mo}_{str(year-1)[2:]}_acft']) < 0, f'WS_C_{mo}_{str(year-1)[2:]}_acft'] = df[f'WS_C_{mo-1}_{str(year-1)[2:]}_acft'] + df[f'IRR_CU_VOLUME_{mo}_{str(year-1)[2:]}_acft']\n",
    "\n",
    "                # new columns to account for adjustments\n",
    "                df[f'IRR_CU_VOLUMEadj_{mo}_{str(year-1)[2:]}_acft'] = df[f'IRR_CU_VOLUME_{mo}_{str(year-1)[2:]}_acft'] + df[f'WS_C_{mo-1}_{str(year-1)[2:]}_acft']\n",
    "                df.loc[(df[f'IRR_CU_VOLUME_{mo}_{str(year-1)[2:]}_acft'] + df[f'WS_C_{mo-1}_{str(year-1)[2:]}_acft']) < 0, f'IRR_CU_VOLUMEadj_{mo}_{str(year-1)[2:]}_acft'] = 0\n",
    "\n",
    "                df[f'EFF_VOLUMEadj_{mo}_{str(year-1)[2:]}_acft'] = df[f'ET_VOLUME_{mo}_{str(year-1)[2:]}_acft'] - df[f'IRR_CU_VOLUMEadj_{mo}_{str(year-1)[2:]}_acft']\n",
    "\n",
    "                \n",
    "                # set AW to be 0\n",
    "                df[f'AW_{mo}_{str(year-1)[2:]}_acft'] = 0\n",
    "\n",
    "                # if the current Net ET is positive, AW is calculated\n",
    "                df.loc[df[f'IRR_CU_VOLUMEadj_{mo}_{str(year-1)[2:]}_acft'] > 0, f'AW_{mo}_{str(year-1)[2:]}_acft'] = df[f'IRR_CU_VOLUMEadj_{mo}_{str(year-1)[2:]}_acft'] / df['IRR_EFF']\n",
    "\n",
    "                # overwrite negative applied water values with 0\n",
    "                df.loc[df[f'AW_{mo}_{str(year-1)[2:]}_acft'] < 0, f'AW_{mo}_{str(year-1)[2:]}_acft'] = 0\n",
    "                \n",
    "                # overwrite AW when irrigation efficiency is 0\n",
    "                df.loc[df['IRR_EFF'] == 0, f'AW_{mo}_{str(year-1)[2:]}_acft'] = np.nan\n",
    "                \n",
    "            elif mo == 12:\n",
    "                \n",
    "                # WS is equal to Net ET when Net ET is negative, overwrite positive WS values below\n",
    "                df[f'WS_{mo}_{str(year-1)[2:]}_acft'] = df[f'IRR_CU_VOLUME_{mo}_{str(year-1)[2:]}_acft']\n",
    "\n",
    "                # if Net ET is positive, overwrite WS to be 0\n",
    "                df.loc[df[f'IRR_CU_VOLUME_{mo}_{str(year-1)[2:]}_acft'] > 0, f'WS_{mo}_{str(year-1)[2:]}_acft'] = 0\n",
    "\n",
    "                # cumulative WS set to 0\n",
    "                df[f'WS_C_{mo}_{str(year-1)[2:]}_acft'] = 0\n",
    "\n",
    "                # if the cumulative WS from previous month plus the current Net ET is negative, current cumulative WS is the sum of previous cumulative WS and current Net ET\n",
    "                df.loc[(df[f'WS_C_{mo-1}_{str(year-1)[2:]}_acft'] + df[f'IRR_CU_VOLUME_{mo}_{str(year-1)[2:]}_acft']) < 0, f'WS_C_{mo}_{str(year-1)[2:]}_acft'] = df[f'WS_C_{mo-1}_{str(year-1)[2:]}_acft'] + df[f'IRR_CU_VOLUME_{mo}_{str(year-1)[2:]}_acft']\n",
    "\n",
    "                # new columns to account for adjustments\n",
    "                df[f'IRR_CU_VOLUMEadj_{mo}_{str(year-1)[2:]}_acft'] = df[f'IRR_CU_VOLUME_{mo}_{str(year-1)[2:]}_acft'] + df[f'WS_C_{mo-1}_{str(year-1)[2:]}_acft']\n",
    "                df.loc[(df[f'IRR_CU_VOLUME_{mo}_{str(year-1)[2:]}_acft'] + df[f'WS_C_{mo-1}_{str(year-1)[2:]}_acft']) < 0, f'IRR_CU_VOLUMEadj_{mo}_{str(year-1)[2:]}_acft'] = 0\n",
    "\n",
    "                df[f'EFF_VOLUMEadj_{mo}_{str(year-1)[2:]}_acft'] = df[f'ET_VOLUME_{mo}_{str(year-1)[2:]}_acft'] - df[f'IRR_CU_VOLUMEadj_{mo}_{str(year-1)[2:]}_acft']\n",
    "                \n",
    "                \n",
    "                # set AW to be 0\n",
    "                df[f'AW_{mo}_{str(year-1)[2:]}_acft'] = 0\n",
    "\n",
    "                # if the current Net ET is positive, AW is calculated\n",
    "                df.loc[df[f'IRR_CU_VOLUMEadj_{mo}_{str(year-1)[2:]}_acft'] > 0, f'AW_{mo}_{str(year-1)[2:]}_acft'] = df[f'IRR_CU_VOLUMEadj_{mo}_{str(year-1)[2:]}_acft'] / df['IRR_EFF']\n",
    "\n",
    "                # overwrite negative applied water values with 0\n",
    "                df.loc[df[f'AW_{mo}_{str(year-1)[2:]}_acft'] < 0, f'AW_{mo}_{str(year-1)[2:]}_acft'] = 0\n",
    "                \n",
    "                # overwrite AW when irrigation efficiency is 0\n",
    "                df.loc[df['IRR_EFF'] == 0, f'AW_{mo}_{str(year-1)[2:]}_acft'] = np.nan\n",
    "                \n",
    "            else:\n",
    "\n",
    "                # WS is equal to Net ET when Net ET is negative, overwrite positive WS values below\n",
    "                df[f'WS_{mo:02d}_{str(year)[2:]}_acft'] = df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft']\n",
    "\n",
    "                # if Net ET is positive, overwrite WS to be 0\n",
    "                df.loc[df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft'] > 0, f'WS_{mo:02d}_{str(year)[2:]}_acft'] = 0\n",
    "\n",
    "                # cumulative WS set to 0\n",
    "                df[f'WS_C_{mo:02d}_{str(year)[2:]}_acft'] = 0\n",
    "\n",
    "                # if the cumulative WS from previous month plus the current Net ET is negative, current cumulative WS is the sum of previous cumulative WS and current Net ET\n",
    "                if mo == 1:\n",
    "                    # january needs to grab a value from previous year\n",
    "                    df.loc[(df[f'WS_C_12_{str(year-1)[2:]}_acft'] + df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft']) < 0, f'WS_C_{mo:02d}_{str(year)[2:]}_acft'] = df[f'WS_C_12_{str(year-1)[2:]}_acft'] + df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft']\n",
    "                \n",
    "                    # new columns to account for adjustments\n",
    "                    df[f'IRR_CU_VOLUMEadj_{mo:02d}_{str(year)[2:]}_acft'] = df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft'] + df[f'WS_C_12_{str(year-1)[2:]}_acft']\n",
    "                    df.loc[(df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft'] + df[f'WS_C_12_{str(year-1)[2:]}_acft']) < 0, f'IRR_CU_VOLUMEadj_{mo:02d}_{str(year)[2:]}_acft'] = 0\n",
    "                else:   \n",
    "                    df.loc[(df[f'WS_C_{(mo-1):02d}_{str(year)[2:]}_acft'] + df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft']) < 0, f'WS_C_{mo:02d}_{str(year)[2:]}_acft'] = df[f'WS_C_{(mo-1):02d}_{str(year)[2:]}_acft'] + df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft']\n",
    "\n",
    "                    # new columns to account for adjustments\n",
    "                    df[f'IRR_CU_VOLUMEadj_{mo:02d}_{str(year)[2:]}_acft'] = df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft'] + df[f'WS_C_{(mo-1):02d}_{str(year)[2:]}_acft']\n",
    "                    df.loc[(df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft'] + df[f'WS_C_{(mo-1):02d}_{str(year)[2:]}_acft']) < 0, f'IRR_CU_VOLUMEadj_{mo:02d}_{str(year)[2:]}_acft'] = 0\n",
    "                    \n",
    "\n",
    "                df[f'EFF_VOLUMEadj_{mo:02d}_{str(year)[2:]}_acft'] = df[f'ET_VOLUME_{mo:02d}_{str(year)[2:]}_acft'] - df[f'IRR_CU_VOLUMEadj_{mo:02d}_{str(year)[2:]}_acft']  \n",
    "                    \n",
    "                # set AW to be 0\n",
    "                df[f'AW_{mo:02d}_{str(year)[2:]}_acft'] = 0\n",
    "\n",
    "                # if the current Net ET plus the current cumulative WS is positive, AW is calculated\n",
    "                if mo == 1:\n",
    "                    df.loc[(df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft'] + df[f'WS_C_{mo:02d}_{str(year)[2:]}_acft']) > 0, f'AW_{mo:02d}_{str(year)[2:]}_acft'] = (df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft'] + df[f'WS_C_12_{str(year-1)[2:]}_acft']) / df['IRR_EFF']\n",
    "                else:\n",
    "                    df.loc[(df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft'] + df[f'WS_C_{mo:02d}_{str(year)[2:]}_acft']) > 0, f'AW_{mo:02d}_{str(year)[2:]}_acft'] = (df[f'IRR_CU_VOLUME_{mo:02d}_{str(year)[2:]}_acft'] + df[f'WS_C_{(mo-1):02d}_{str(year)[2:]}_acft']) / df['IRR_EFF']\n",
    "                \n",
    "                # overwrite negative applied water values with 0\n",
    "                df.loc[df[f'AW_{mo:02d}_{str(year)[2:]}_acft'] < 0, f'AW_{mo:02d}_{str(year)[2:]}_acft'] = 0\n",
    "                \n",
    "                # overwrite AW when irrigation efficiency is 0\n",
    "                df.loc[df['IRR_EFF'] == 0, f'AW_{mo:02d}_{str(year)[2:]}_acft'] = np.nan\n",
    "                \n",
    "                if mo == 10:\n",
    "                    \n",
    "                    df_cf['WS_C_Carry_Forward'] = df[f'WS_C_10_{str(year)[2:]}_acft']\n",
    "                \n",
    "    # flip the sign of the water surplus\n",
    "    df[f'WS_C_11_{str(year-1)[2:]}_acft'] = df[f'WS_C_11_{str(year-1)[2:]}_acft'] * -1\n",
    "    df[f'WS_C_12_{str(year-1)[2:]}_acft'] = df[f'WS_C_12_{str(year-1)[2:]}_acft'] * -1\n",
    "    df[f'WS_C_01_{str(year)[2:]}_acft'] = df[f'WS_C_01_{str(year)[2:]}_acft'] * -1\n",
    "    df[f'WS_C_02_{str(year)[2:]}_acft'] = df[f'WS_C_02_{str(year)[2:]}_acft'] * -1\n",
    "    df[f'WS_C_03_{str(year)[2:]}_acft'] = df[f'WS_C_03_{str(year)[2:]}_acft'] * -1\n",
    "    df[f'WS_C_04_{str(year)[2:]}_acft'] = df[f'WS_C_04_{str(year)[2:]}_acft'] * -1\n",
    "    df[f'WS_C_05_{str(year)[2:]}_acft'] = df[f'WS_C_05_{str(year)[2:]}_acft'] * -1\n",
    "    df[f'WS_C_06_{str(year)[2:]}_acft'] = df[f'WS_C_06_{str(year)[2:]}_acft'] * -1\n",
    "    df[f'WS_C_07_{str(year)[2:]}_acft'] = df[f'WS_C_07_{str(year)[2:]}_acft'] * -1\n",
    "    df[f'WS_C_08_{str(year)[2:]}_acft'] = df[f'WS_C_08_{str(year)[2:]}_acft'] * -1\n",
    "    df[f'WS_C_09_{str(year)[2:]}_acft'] = df[f'WS_C_09_{str(year)[2:]}_acft'] * -1\n",
    "    df[f'WS_C_10_{str(year)[2:]}_acft'] = df[f'WS_C_10_{str(year)[2:]}_acft'] * -1\n",
    "    \n",
    "    \n",
    "    if year == 1985:\n",
    "        df_out = df.drop([f'WS_11_{str(year-1)[2:]}_acft', f'WS_12_{str(year-1)[2:]}_acft', f'WS_01_{str(year)[2:]}_acft',\n",
    "                          f'WS_02_{str(year)[2:]}_acft', f'WS_03_{str(year)[2:]}_acft', f'WS_04_{str(year)[2:]}_acft',\n",
    "                          f'WS_05_{str(year)[2:]}_acft', f'WS_06_{str(year)[2:]}_acft', f'WS_07_{str(year)[2:]}_acft',\n",
    "                          f'WS_08_{str(year)[2:]}_acft', f'WS_09_{str(year)[2:]}_acft', f'WS_10_{str(year)[2:]}_acft'], axis=1)\n",
    "    else:\n",
    "        df_out = df.drop([f'WS_11_{str(year-1)[2:]}_acft', f'WS_12_{str(year-1)[2:]}_acft', f'WS_01_{str(year)[2:]}_acft',\n",
    "                          f'WS_02_{str(year)[2:]}_acft', f'WS_03_{str(year)[2:]}_acft', f'WS_04_{str(year)[2:]}_acft',\n",
    "                          f'WS_05_{str(year)[2:]}_acft', f'WS_06_{str(year)[2:]}_acft', f'WS_07_{str(year)[2:]}_acft',\n",
    "                          f'WS_08_{str(year)[2:]}_acft', f'WS_09_{str(year)[2:]}_acft', f'WS_10_{str(year)[2:]}_acft',\n",
    "                          f'WS_C_10_{str(year-1)[2:]}_acft'], axis=1)\n",
    "    \n",
    "    # fill any null values with 0's\n",
    "    df_out.loc[:, :] = df_out.fillna(0)\n",
    "    \n",
    "    df_out = df_out.reset_index()\n",
    "\n",
    "    df_out.to_csv(os.path.join(out_path, f'or_openet_etdemands_monthly_water_year_shift_1mo_{year}_final.csv'), index=False)\n",
    "    \n",
    "    print(f'exported file for {year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7768dd8c-3daa-4ca7-8b73-30a1be16ffb9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. HUC8/HUC12 aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba66ef82-9565-4b04-87f1-aa7c9f282022",
   "metadata": {},
   "source": [
    "### First, select the HUC-level and the irrigation source type filtering if needed (e.g., no filtering=\"all\" and groundwater sources only=\"groundwater\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18119c9b-2fc2-401d-9180-13b45d92388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "\n",
    "# specify the HUC-level to process (HUC8 or HUC12)\n",
    "huc_level = 'HUC8'\n",
    "\n",
    "# filter by irrigation source type (all, groundwater, or surface_water)\n",
    "# \"all\" does not do any filtering of irrigation source type and includes all fields\n",
    "src_type = 'all'\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "if not (huc_level == 'HUC8' or huc_level == 'HUC12'):\n",
    "    print('huc_level must equal HUC8 or HUC12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8557583-add1-43f9-9585-6440340453b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "in_path = table_path.replace('ee_exports', 'post_processing\\\\5_field_geodatabase')\n",
    "\n",
    "out_path = table_path.replace('ee_exports', 'post_processing\\\\6_huc_geodatabase')\n",
    "\n",
    "# list of years based on start/end year parameters\n",
    "year_list = list(range(start_year, end_year+1))\n",
    "\n",
    "# irrmapper irrigated filter (>40 % of the field-area is considered irrigated)\n",
    "irr_val = 40\n",
    "\n",
    "# irrmapper wetland filter\n",
    "wetland_val = 40\n",
    "\n",
    "df_out = pd.DataFrame([])\n",
    "\n",
    "\n",
    "for yr in yr_list:\n",
    "\n",
    "    # read file into a dataframe\n",
    "    df_1 = pd.read_csv(os.path.join(in_path, f'or_openet_etdemands_monthly_water_year_shift_1mo_{yr}_final.csv'))\n",
    "\n",
    "    # filter fields using IrrMapper irrigated > 40% OR (IrrMapper wetland > 40% & srctype non zero & EToF not equal to 1)\n",
    "    df_1 = df_1.loc[(df_1[f'%_IRRIGATED_{str(yr)[2:]}'] > irr_val) | ((df_1[f'%_IRRIGATED_{str(yr)[2:]}'] <= irr_val) & (df_1[f'%_WETLAND_{str(yr)[2:]}'] > wetland_val) & (df_1['srctype'] != 0) & (df_1[f'ETOF_IRR_STATUS_{str(yr)[2:]}_MODE'].isin([2,3,5])))]\n",
    "\n",
    "    # irrigation source type filtering\n",
    "    if src_type == 'groundwater':\n",
    "        df_1 = df_1.loc[df_1['srctype'].isin([1, 3])]\n",
    "    elif src_type == 'surface_water':\n",
    "        df_1 = df_1.loc[df_1['srctype'].isin([2, 3])]\n",
    "\n",
    "    \n",
    "    df_1[f'ACRES_{str(yr)[2:]}'] = df_1[f'ACRES_FTR_GEOM_{str(yr)[2:]}']\n",
    "    # # sum monthly column values to get annual totals for each field/row\n",
    "    df_1[f'ET_v_{str(yr)[2:]}'] = df_1.loc[:, df_1.columns.str.contains('ET_VOLUME')].sum(axis=1)\n",
    "    df_1[f'ETc_v_{str(yr)[2:]}'] = df_1.loc[:, df_1.columns.str.contains('ETDa_VOLUME')].sum(axis=1)\n",
    "    df_1[f'ETo_v_{str(yr)[2:]}'] = df_1.loc[:, df_1.columns.str.contains('ETO_VOLUME')].sum(axis=1)\n",
    "    df_1[f'PPT_v_{str(yr)[2:]}'] = df_1.loc[:, df_1.columns.str.contains('PPT_VOLUME')].sum(axis=1)\n",
    "    df_1[f'EFF_v_{str(yr)[2:]}'] = df_1.loc[:, df_1.columns.str.contains('EFF_VOLUMEadj')].sum(axis=1)\n",
    "    df_1[f'NIWR_v_{str(yr)[2:]}'] = df_1.loc[:, df_1.columns.str.contains('NIWR_VOLUME')].sum(axis=1)\n",
    "    df_1[f'CU_v_{str(yr)[2:]}'] = df_1.loc[:, df_1.columns.str.contains('IRR_CU_VOLUMEadj')].sum(axis=1)\n",
    "    df_1[f'AW_v_{str(yr)[2:]}'] = df_1.loc[:, df_1.columns.str.contains('AW_')].sum(axis=1)\n",
    "\n",
    "    # locate mix source type fields and threshold the ET, EFF, CU and AW to be half to split surface/groundwater\n",
    "    if (src_type == 'groundwater' or src_type == 'surface_water'):\n",
    "        df_1.loc[df_1['srctype'] == 3, f'ET_v_{str(yr)[2:]}'] = df_1[f'ET_v_{str(yr)[2:]}'] * 0.5\n",
    "        df_1.loc[df_1['srctype'] == 3, f'ETc_v_{str(yr)[2:]}'] = df_1[f'ETc_v_{str(yr)[2:]}'] * 0.5\n",
    "        df_1.loc[df_1['srctype'] == 3, f'ETo_v_{str(yr)[2:]}'] = df_1[f'ETo_v_{str(yr)[2:]}'] * 0.5\n",
    "        df_1.loc[df_1['srctype'] == 3, f'PPT_v_{str(yr)[2:]}'] = df_1[f'PPT_v_{str(yr)[2:]}'] * 0.5\n",
    "        df_1.loc[df_1['srctype'] == 3, f'EFF_v_{str(yr)[2:]}'] = df_1[f'EFF_v_{str(yr)[2:]}'] * 0.5\n",
    "        df_1.loc[df_1['srctype'] == 3, f'NIWR_v_{str(yr)[2:]}'] = df_1[f'NIWR_v_{str(yr)[2:]}'] * 0.5\n",
    "        df_1.loc[df_1['srctype'] == 3, f'CU_v_{str(yr)[2:]}'] = df_1[f'CU_v_{str(yr)[2:]}'] * 0.5\n",
    "        df_1.loc[df_1['srctype'] == 3, f'AW_v_{str(yr)[2:]}'] = df_1[f'AW_v_{str(yr)[2:]}'] * 0.5\n",
    "\n",
    "    # groupby each huc or region and sum up the volumes\n",
    "    df_1_group1 = df_1[[f'ACRES_{str(yr)[2:]}', f'ET_v_{str(yr)[2:]}', f'ETc_v_{str(yr)[2:]}', f'ETo_v_{str(yr)[2:]}', f'PPT_v_{str(yr)[2:]}', f'EFF_v_{str(yr)[2:]}',\n",
    "                        f'NIWR_v_{str(yr)[2:]}', f'CU_v_{str(yr)[2:]}', f'AW_v_{str(yr)[2:]}', f'{huc_level}']].groupby(f'{huc_level}').sum()\n",
    "    \n",
    "    \n",
    "    df_1_group1[f'ET_r_{str(yr)[2:]}'] = df_1_group1[f'ET_v_{str(yr)[2:]}'] / df_1_group1[f'ACRES_{str(yr)[2:]}']\n",
    "    df_1_group1[f'ETc_r_{str(yr)[2:]}'] = df_1_group1[f'ETc_v_{str(yr)[2:]}'] / df_1_group1[f'ACRES_{str(yr)[2:]}']\n",
    "    df_1_group1[f'ETo_r_{str(yr)[2:]}'] = df_1_group1[f'ETo_v_{str(yr)[2:]}'] / df_1_group1[f'ACRES_{str(yr)[2:]}']\n",
    "    df_1_group1[f'PPT_r_{str(yr)[2:]}'] = df_1_group1[f'PPT_v_{str(yr)[2:]}'] / df_1_group1[f'ACRES_{str(yr)[2:]}']\n",
    "    df_1_group1[f'EFF_r_{str(yr)[2:]}'] = df_1_group1[f'EFF_v_{str(yr)[2:]}'] / df_1_group1[f'ACRES_{str(yr)[2:]}']\n",
    "    df_1_group1[f'NIWR_r_{str(yr)[2:]}'] = df_1_group1[f'NIWR_v_{str(yr)[2:]}'] / df_1_group1[f'ACRES_{str(yr)[2:]}']\n",
    "    df_1_group1[f'CU_r_{str(yr)[2:]}'] = df_1_group1[f'CU_v_{str(yr)[2:]}'] / df_1_group1[f'ACRES_{str(yr)[2:]}']   \n",
    "    df_1_group1[f'AW_r_{str(yr)[2:]}'] = df_1_group1[f'AW_v_{str(yr)[2:]}'] / df_1_group1[f'ACRES_{str(yr)[2:]}']\n",
    "\n",
    "\n",
    "    df_1_group2 = df_1[[f'{huc_level}_name', f'{huc_level}']].groupby(f'{huc_level}').first()\n",
    "\n",
    "    df = pd.concat([df_1_group2, df_1_group1], axis=1)\n",
    "\n",
    "    data = [df_out, df]\n",
    "    df_out = pd.concat(data, axis=1)\n",
    "    df_out = df_out.loc[:, ~df_out.columns.duplicated()].copy()\n",
    "\n",
    "df_out = df_out.loc[:, ~df_out.columns.duplicated()].copy()\n",
    "df_out = df_out.reset_index()\n",
    "df_out = df_out.set_index([f'{huc_level}', f'{huc_level}_name'])\n",
    "df_out = df_out.reset_index()\n",
    "\n",
    "    \n",
    "# long-term average of the area-weighted average Nov-Oct rates and volumes\n",
    "# df_out.replace(\"\", np.nan, inplace=True)\n",
    "df_out['ET_v'] = df_out.loc[:, df_out.columns.str.contains('ET_v')].mean(axis=1)\n",
    "df_out['ET_r'] = df_out.loc[:, df_out.columns.str.contains('ET_r')].mean(axis=1)\n",
    "df_out['ETc_v'] = df_out.loc[:, df_out.columns.str.contains('ETc_v')].mean(axis=1)\n",
    "df_out['ETc_r'] = df_out.loc[:, df_out.columns.str.contains('ETc_r')].mean(axis=1)\n",
    "df_out['ETo_v'] = df_out.loc[:, df_out.columns.str.contains('ETo_v')].mean(axis=1)\n",
    "df_out['ETo_r'] = df_out.loc[:, df_out.columns.str.contains('ETo_r')].mean(axis=1)\n",
    "df_out['PPT_v'] = df_out.loc[:, df_out.columns.str.contains('PPT_v')].mean(axis=1)\n",
    "df_out['PPT_r'] = df_out.loc[:, df_out.columns.str.contains('PPT_r')].mean(axis=1)\n",
    "df_out['EFF_v'] = df_out.loc[:, df_out.columns.str.contains('EFF_v')].mean(axis=1)\n",
    "df_out['EFF_r'] = df_out.loc[:, df_out.columns.str.contains('EFF_r')].mean(axis=1)\n",
    "df_out['NIWR_v'] = df_out.loc[:, df_out.columns.str.contains('NIWR_v')].mean(axis=1)\n",
    "df_out['NIWR_r'] = df_out.loc[:, df_out.columns.str.contains('NIWR_r')].mean(axis=1)\n",
    "df_out['CUirr_v'] = df_out.loc[:, df_out.columns.str.contains('CU_v')].mean(axis=1)\n",
    "df_out['CUirr_r'] = df_out.loc[:, df_out.columns.str.contains('CU_r')].mean(axis=1)    \n",
    "df_out['AW_v'] = df_out.loc[:, df_out.columns.str.contains('AW_v')].mean(axis=1)\n",
    "df_out['AW_r'] = df_out.loc[:, df_out.columns.str.contains('AW_r')].mean(axis=1)   \n",
    "    \n",
    "df_out.to_csv(os.path.join(out_path, fr'or_{huc_level.lower()}_openet_etdemands_water_year_shift_1mo_srctype_{src_type}.csv'), index=False)\n",
    "print(f'exported {huc_level.lower()} {src_type} table')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980d05c-c04d-45b1-ae6e-8f69dd816c1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 6. HUC-level geodatabase preparation with Google Earth Engine (GEE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49baaec1-6d15-4d6d-880c-66fca8277499",
   "metadata": {},
   "source": [
    "### First, you must upload the HUC8 and/or HUC12 CSVs from the previous step to GEE\n",
    "1. Navigate to the javascript code editor ([GEE](https://code.earthengine.google.com/))<br>\n",
    "2. On the Assets tab in the top left corner, click \"New\" and \"CSV file (.csv)\"<br>\n",
    "3. Upload the HUC table to the location of your choice and use the same name as the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5073d55-769f-43e7-98c4-bd47e316214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------\n",
    "\n",
    "# you must use a registered google cloud project to enable GEE access\n",
    "gcloud_project_id = 'ee-bminor'\n",
    "\n",
    "# export data to cloud_storage or google_drive\n",
    "export_location = 'google_drive'\n",
    "\n",
    "### ONLY USED IF EXPORTING DATA TOa CLOUD STORAGE\n",
    "# path to cloud storage bucket if exporting data to cloud storage\n",
    "gcloud_path = \"openet/intercomparison/output_main/Oregon_Statewide_2023/huc_summaries\"\n",
    "\n",
    "\n",
    "# specify the HUC-level to process (HUC8 or HUC12)\n",
    "huc_level = 'HUC8'\n",
    "\n",
    "# filter by irrigation source type (all, groundwater, or surface_water)\n",
    "# \"all\" does not do any filtering of irrigation source type and includes all fields\n",
    "src_type = 'all'\n",
    "\n",
    "# specify the assetID/path to the HUC-level CSV table (all years that were processed previously) that was uploaded to Google Earth Engine\n",
    "ee_assetID = f'users/bminor-dri/OR/OWRD_Statewide_ET/tables/or_{huc_level.lower()}_openet_etdemands_water_year_shift_1mo_srctype_{src_type}'\n",
    "\n",
    "#---------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afa8a90-3870-4d5f-8586-669a3bae5374",
   "metadata": {},
   "source": [
    "### Import and initialize the GEE API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51481c0f-a438-4a6c-9ba8-b736549038d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "# ee.Authenticate()\n",
    "ee.Initialize(project=gcloud_project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e34ec1-873b-48c4-84ed-21f3f0cb3a1a",
   "metadata": {},
   "source": [
    "### Create the feature collection/shapefile from the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d0278-1c72-4264-81f3-6621b9976911",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# spatial aggregation dictionary\n",
    "huc_dict = {\n",
    "    'HUC8': 'USGS/WBD/2017/HUC08',\n",
    "    'HUC12': 'USGS/WBD/2017/HUC12',\n",
    "}\n",
    "\n",
    "def cleanJoin(ftr):\n",
    "    return ee.Feature(ftr.get('primary')).copyProperties(ftr.get('secondary'))\n",
    "\n",
    "if huc_level == 'HUC8':\n",
    "    def setProp(ftr):\n",
    "        prop = ee.Number.parse(ftr.get('HUC8')).format()\n",
    "        return ftr.set({\n",
    "            'huc_str': prop,\n",
    "        })\n",
    "elif huc_level == 'HUC12':\n",
    "    def setProp(ftr):\n",
    "        prop = ee.Number.parse(ftr.get('HUC12')).format()\n",
    "        return ftr.set({\n",
    "            'huc_str': prop,\n",
    "        })\n",
    "else:\n",
    "    print('wrong huc_level set, please check the parameters')\n",
    "\n",
    "\n",
    "# feature collection with geometries to merge stats with\n",
    "base_fc = (\n",
    "    ee.FeatureCollection(huc_dict[huc_level])\n",
    "        .select([huc_level.lower()], [huc_level])\n",
    ")\n",
    "\n",
    "# Define a spatial filter\n",
    "Filter = ee.Filter.equals(\n",
    "    leftField=huc_level,\n",
    "    rightField='huc_str',\n",
    ")\n",
    "\n",
    "# inner join (matches only)\n",
    "saveAllJoin = ee.Join.inner()\n",
    "\n",
    "# just the name from the assetID\n",
    "in_asset_name = ee_assetID.split('/')[-1]\n",
    "\n",
    "# output assetID for the shapefile/feature collection\n",
    "out_asset_id = ee_assetID.replace(in_asset_name, f'or_openet_{huc_level.lower()}_irrigated_{src_type}')\n",
    "\n",
    "table_stats = ee.FeatureCollection(ee_assetID).map(setProp)\n",
    "\n",
    "# Apply the join.\n",
    "joined = ee.FeatureCollection(saveAllJoin.apply(base_fc, table_stats, Filter))\n",
    "\n",
    "# clean the joined collection\n",
    "output = joined.map(cleanJoin).set('huc_str', None)\n",
    "\n",
    "# Export an ee.FeatureCollection as an Earth Engine asset.        \n",
    "out_task = ee.batch.Export.table.toAsset(**{\n",
    "    'collection': output,\n",
    "    'description': f'or_spatial_join_{huc_level}_{src_type}_ToTableAsset',\n",
    "    'assetId': out_asset_id,\n",
    "})\n",
    "out_task.start()\n",
    "\n",
    "print(f'task started for {huc_level} {src_type} irrigation source types')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d85f69a-959f-4e57-936e-5fcd56c33f2b",
   "metadata": {},
   "source": [
    "### Export the feature collection that was created during the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a58aad0-557a-4430-b418-3e880c582426",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# redefine the location of the HUC asset in case the session was restarted since the creation of the feature collection\n",
    "out_asset_id = ee_assetID.replace(in_asset_name, f'or_openet_{huc_level.lower()}_irrigated_{src_type}')\n",
    "\n",
    "out_ftr_coll = ee.FeatureCollection(out_asset_id)\n",
    "\n",
    "# Export tasks\n",
    "if export_location == 'google_drive':\n",
    "\n",
    "    # Export a CSV file to Google Drive.\n",
    "    out_table_task = ee.batch.Export.table.toDrive(**{\n",
    "        'collection': out_ftr_coll,\n",
    "        'description': f'OR_{huc_level}_{src_type}_Shapefile_Export',\n",
    "        'fileNamePrefix': f'or_openet_{huc_level.lower()}_irrigated_{src_type}',\n",
    "        'fileFormat': 'SHP',\n",
    "    })\n",
    "\n",
    "elif export_location == 'cloud_storage':\n",
    "    \n",
    "    # Export a CSV file to Cloud Storage.\n",
    "    out_table_task = ee.batch.Export.table.toCloudStorage(**{\n",
    "        'collection': out_ftr_coll,\n",
    "        'description': f'OR_{huc_level}_{src_type}_Shapefile_Export',\n",
    "        'bucket': gcloud_path.split('/')[0],\n",
    "        'fileNamePrefix': f'{gcloud_path}/or_openet_{huc_level.lower()}_irrigated_{src_type}',\n",
    "        'fileFormat': 'SHP',\n",
    "     })\n",
    "\n",
    "else:\n",
    "    print('wrong export location setting, please check the parameter')\n",
    "\n",
    "out_table_task.start()\n",
    "print(f'exported shapefile from GEE for {huc_level} {src_type} irrigation source types')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
